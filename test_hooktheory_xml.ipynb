{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zlib\n",
    "import muspy as mp\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from harmony_tokenizers import ChordSymbolTokenizer, RootTypeTokenizer, \\\n",
    "    PitchClassTokenizer, RootPCTokenizer, \\\n",
    "    GCTRootPCTokenizer, GCTSymbolTokenizer, GCTRootTypeTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files from Hook Theory dataset: 17476\n"
     ]
    }
   ],
   "source": [
    "root_dir = './hooktheory_dataset/xmls/'\n",
    "data_files = []\n",
    "\n",
    "# Walk through all subdirectories and files\n",
    "for dirpath, _, filenames in os.walk(root_dir):\n",
    "    for file in filenames:\n",
    "        if file.endswith(\".xml\"):\n",
    "            full_path = os.path.join(dirpath, file)\n",
    "            data_files.append(full_path)\n",
    "\n",
    "print('Total files from Hook Theory dataset:', len(data_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 5880/17476 [00:30<00:58, 199.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file: ./hooktheory_dataset/xmls/h\\hiroshi-miyagawa\\space-battleship-yamato---autoplanet-goruba\\verse.xml\n",
      "Error: '7(b5)'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17476/17476 [01:38<00:00, 178.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files processed:  17475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#load files\n",
    "hk_pieces = []\n",
    "for i in tqdm(range(len(data_files))):\n",
    "    try:\n",
    "        g = mp.read_musicxml(data_files[i])\n",
    "        hk_pieces.append(g)\n",
    "    except Exception as e:\n",
    "        #catch very rare chord exceptions\n",
    "        print(f\"Error processing file: {data_files[i]}\")\n",
    "        print(f\"Error: {e}\")        \n",
    "\n",
    "print('Total files processed: ', len(hk_pieces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare stats\n",
    "stats = {}\n",
    "\n",
    "def compute_compression_rate(array: np.ndarray, compression_method=zlib.compress) -> float:\n",
    "    \"\"\"\n",
    "    Compute the compression rate of a NumPy array.\n",
    "\n",
    "    Parameters:\n",
    "        array (np.ndarray): The NumPy array to compress.\n",
    "        compression_method (callable): The compression method to use. \n",
    "                                       Default is `zlib.compress`.\n",
    "\n",
    "    Returns:\n",
    "        float: The compression rate (compressed size / original size).\n",
    "    \"\"\"\n",
    "    # Convert the array to bytes\n",
    "    array_bytes = array.tobytes()\n",
    "    \n",
    "    # Compress the byte representation\n",
    "    compressed_bytes = compression_method(array_bytes)\n",
    "    \n",
    "    # Compute sizes\n",
    "    original_size = len(array_bytes)\n",
    "    compressed_size = len(compressed_bytes)\n",
    "    \n",
    "    # Calculate compression rate\n",
    "    compression_rate = compressed_size / original_size\n",
    "\n",
    "    return compression_rate\n",
    "\n",
    "def initialize_stats(key, tokenizer):\n",
    "    stats[key] = {\n",
    "        'vocab_size': len(tokenizer.vocab),\n",
    "        'seq_lens': [],\n",
    "        'compression_rates': []\n",
    "    }\n",
    "# end initialize_stats\n",
    "\n",
    "def update_stats(key, toks):\n",
    "    for t in toks['ids']:\n",
    "        stats[key]['seq_lens'].append( len(t) )\n",
    "        stats[key]['compression_rates'].append( compute_compression_rate(np.array(t)) )\n",
    "    stats[key]['mean_len'] = np.mean(stats[key]['seq_lens'])\n",
    "    stats[key]['std_len'] = np.std(stats[key]['seq_lens'])\n",
    "    stats[key]['mean_compression'] = np.mean(stats[key]['compression_rates'])\n",
    "    stats[key]['std_compression'] = np.std(stats[key]['compression_rates'])\n",
    "# end update_stats\n",
    "\n",
    "def print_stats(key):\n",
    "    print('vocab_size: ', stats[key]['vocab_size'])\n",
    "    print('mean len: ', stats[key]['mean_len'])\n",
    "    print('std len: ', stats[key]['std_len'])\n",
    "    print('mean cr: ', stats[key]['mean_compression'])\n",
    "    print('std cr: ', stats[key]['std_compression'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChordSymbolTokenizer\n",
      "len(chordSymbolTokenizer.vocab):  326\n",
      "example sentence length:  82\n",
      "['bar', 'position_0x0', 'C:maj', 'bar', 'position_0x0', 'C:maj', 'position_0x0', 'C:maj', 'bar', 'position_0x0', 'C:maj', 'position_0x0', 'C:maj', 'position_0x0', 'C:maj', 'position_0x0', 'A:min', 'bar', 'position_0x0', 'A:min', 'position_0x0', 'A:min', 'position_0x0', 'F:maj', 'position_3x0', 'F:maj', 'position_3x0', 'F:maj', 'bar', 'position_0x0', 'C:maj', 'bar', 'position_0x0', 'C:maj', 'position_0x0', 'C:maj', 'bar', 'position_0x0', 'C:maj', 'position_0x0', 'C:maj', 'position_0x0', 'C:maj', 'position_0x0', 'A:min', 'bar', 'position_0x0', 'A:min', 'position_0x0', 'A:min', 'position_0x0', 'F:maj', 'bar', 'position_0x0', 'F:maj', 'position_0x0', 'F:maj', 'position_0x0', 'F:maj', 'position_0x0', 'C:maj', 'bar', 'position_0x0', 'C:maj', 'bar', 'position_0x0', 'A:min', 'bar', 'position_0x0', 'F:maj', 'bar', 'position_0x0', 'C:maj', 'bar', 'position_0x0', 'C:maj', 'bar', 'position_0x0', 'A:min', 'bar', 'position_0x0', 'F:maj']\n",
      "[5, 6, 26, 5, 6, 26, 6, 26, 5, 6, 26, 6, 26, 6, 26, 6, 252, 5, 6, 252, 6, 252, 6, 151, 12, 151, 12, 151, 5, 6, 26, 5, 6, 26, 6, 26, 5, 6, 26, 6, 26, 6, 26, 6, 252, 5, 6, 252, 6, 252, 6, 151, 5, 6, 151, 6, 151, 6, 151, 6, 26, 5, 6, 26, 5, 6, 252, 5, 6, 151, 5, 6, 26, 5, 6, 26, 5, 6, 252, 5, 6, 151]\n",
      "vocab_size:  326\n",
      "mean len:  47.00932814467208\n",
      "std len:  30.55923523521828\n",
      "mean cr:  0.28700821025486484\n",
      "std cr:  0.106001113303193\n"
     ]
    }
   ],
   "source": [
    "print('ChordSymbolTokenizer')\n",
    "chordSymbolTokenizer = ChordSymbolTokenizer()\n",
    "print('len(chordSymbolTokenizer.vocab): ', len(chordSymbolTokenizer.vocab))\n",
    "initialize_stats('ChordSymbolTokenizer', chordSymbolTokenizer)\n",
    "toks_cs = chordSymbolTokenizer(hk_pieces)\n",
    "print('example sentence length: ', len(toks_cs['tokens'][0]))\n",
    "print(toks_cs['tokens'][0])\n",
    "print(toks_cs['ids'][0])\n",
    "update_stats('ChordSymbolTokenizer', toks_cs)\n",
    "print_stats('ChordSymbolTokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RootTypeTokenizer')\n",
    "rootTypeTokenizer = RootTypeTokenizer()\n",
    "print('len(rootTypeTokenizer.vocab): ', len(rootTypeTokenizer.vocab))\n",
    "initialize_stats('RootTypeTokenizer', rootTypeTokenizer)\n",
    "toks_rt = rootTypeTokenizer(gjt_pieces)\n",
    "print('example sentence length: ', len(toks_rt['tokens'][0]))\n",
    "print(toks_rt['tokens'][0])\n",
    "print(toks_rt['ids'][0])\n",
    "update_stats('RootTypeTokenizer', toks_rt)\n",
    "print_stats('RootTypeTokenizer')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
