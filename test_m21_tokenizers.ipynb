{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import zlib\n",
    "import numpy as np\n",
    "from harmony_tokenizers_m21 import ChordSymbolTokenizer, MelodyPitchTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files from Hook Theory dataset: 650\n"
     ]
    }
   ],
   "source": [
    "# root_dir = '/media/datadisk/datasets/hooktheory_xmls'\n",
    "root_dir = 'data/gjt_melodies/Library_melodies/'\n",
    "data_files = []\n",
    "\n",
    "# Walk through all subdirectories and files\n",
    "for dirpath, _, filenames in os.walk(root_dir):\n",
    "    for file in filenames:\n",
    "        if file.endswith('.xml') or file.endswith('.mxl'):\n",
    "            full_path = os.path.join(dirpath, file)\n",
    "            data_files.append(full_path)\n",
    "\n",
    "print('Total files from Hook Theory dataset:', len(data_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare stats\n",
    "stats = {}\n",
    "\n",
    "def compute_compression_rate(array: np.ndarray, compression_method=zlib.compress) -> float:\n",
    "    \"\"\"\n",
    "    Compute the compression rate of a NumPy array.\n",
    "\n",
    "    Parameters:\n",
    "        array (np.ndarray): The NumPy array to compress.\n",
    "        compression_method (callable): The compression method to use. \n",
    "                                       Default is `zlib.compress`.\n",
    "\n",
    "    Returns:\n",
    "        float: The compression rate (compressed size / original size).\n",
    "    \"\"\"\n",
    "    # Convert the array to bytes\n",
    "    array_bytes = array.tobytes()\n",
    "    \n",
    "    # Compress the byte representation\n",
    "    compressed_bytes = compression_method(array_bytes)\n",
    "    \n",
    "    # Compute sizes\n",
    "    original_size = len(array_bytes)\n",
    "    compressed_size = len(compressed_bytes)\n",
    "    \n",
    "    # Calculate compression rate\n",
    "    compression_rate = compressed_size / original_size\n",
    "\n",
    "    return compression_rate\n",
    "\n",
    "def initialize_stats(key, tokenizer):\n",
    "    stats[key] = {\n",
    "        'vocab_size': len(tokenizer.vocab),\n",
    "        'seq_lens': [],\n",
    "        'compression_rates': []\n",
    "    }\n",
    "# end initialize_stats\n",
    "\n",
    "def update_stats(key, toks):\n",
    "    for t in toks['ids']:\n",
    "        stats[key]['seq_lens'].append( len(t) )\n",
    "        stats[key]['compression_rates'].append( compute_compression_rate(np.array(t)) )\n",
    "    stats[key]['mean_len'] = np.mean(stats[key]['seq_lens'])\n",
    "    stats[key]['std_len'] = np.std(stats[key]['seq_lens'])\n",
    "    stats[key]['mean_compression'] = np.mean(stats[key]['compression_rates'])\n",
    "    stats[key]['std_compression'] = np.std(stats[key]['compression_rates'])\n",
    "# end update_stats\n",
    "\n",
    "def print_stats(key):\n",
    "    print('vocab_size: ', stats[key]['vocab_size'])\n",
    "    print('mean len: ', stats[key]['mean_len'])\n",
    "    print('std len: ', stats[key]['std_len'])\n",
    "    print('mean cr: ', stats[key]['mean_compression'])\n",
    "    print('std cr: ', stats[key]['std_compression'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChordSymbolTokenizer_m21\n",
      "len(chordSymbolTokenizer.vocab):  444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files:  79%|███████▉  | 516/650 [00:38<00:10, 13.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<music21.harmony.ChordSymbol B#9 alter #5>\n",
      "B#\n",
      "whole-tone pentachord\n",
      "File 'data/gjt_melodies/Library_melodies/You_re_Everything.mxl' generated 1 'unk' tokens.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files: 100%|██████████| 650/650 [00:48<00:00, 13.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example sentence length:  88\n",
      "['bar', 'position_0x00', 'A:min7', 'bar', 'position_0x00', 'D:7', 'bar', 'position_0x00', 'A:min7', 'bar', 'position_0x00', 'D:7', 'bar', 'position_0x00', 'G:maj7', 'bar', 'position_0x00', 'C:7(#11)', 'bar', 'position_0x00', 'B:min7', 'bar', 'position_0x00', 'E:min7', 'bar', 'position_0x00', 'B:maj7', 'position_2x00', 'F#:7', 'bar', 'position_0x00', 'B:maj6', 'bar', 'position_0x00', 'D:min7', 'bar', 'position_0x00', 'G:7', 'bar', 'position_0x00', 'D:min7', 'bar', 'position_0x00', 'G:7', 'bar', 'position_0x00', 'C:maj7', 'bar', 'position_0x00', 'F:7', 'bar', 'position_0x00', 'E:min7', 'position_2x00', 'A:7', 'bar', 'position_0x00', 'A:min7', 'position_2x00', 'D:7', 'bar', 'position_0x00', 'A:min7', 'bar', 'position_0x00', 'D:7', 'bar', 'position_0x00', 'G:maj7', 'position_2x00', 'F:7', 'bar', 'position_0x00', 'E:7(b9)', 'bar', 'position_0x00', 'A:min7', 'bar', 'position_0x00', 'F:7', 'bar', 'position_0x00', 'A:min7', 'position_2x00', 'D:7', 'bar', 'position_0x00', 'G:maj6']\n",
      "[5, 6, 365, 5, 6, 160, 5, 6, 365, 5, 6, 160, 5, 6, 306, 5, 6, 123, 5, 6, 423, 5, 6, 220, 5, 6, 422, 24, 276, 5, 6, 425, 5, 6, 162, 5, 6, 305, 5, 6, 162, 5, 6, 305, 5, 6, 103, 5, 6, 247, 5, 6, 220, 24, 363, 5, 6, 365, 24, 160, 5, 6, 365, 5, 6, 160, 5, 6, 306, 24, 247, 5, 6, 237, 5, 6, 365, 5, 6, 247, 5, 6, 365, 24, 160, 5, 6, 309]\n",
      "vocab_size:  444\n",
      "mean len:  103.60307692307693\n",
      "std len:  34.29661552815949\n",
      "mean cr:  0.11675020033137182\n",
      "std cr:  0.025943086298484744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('ChordSymbolTokenizer_m21')\n",
    "chordSymbolTokenizer = ChordSymbolTokenizer()\n",
    "print('len(chordSymbolTokenizer.vocab): ', len(chordSymbolTokenizer.vocab))\n",
    "initialize_stats('ChordSymbolTokenizer', chordSymbolTokenizer)\n",
    "toks_cs = chordSymbolTokenizer(data_files)\n",
    "print('example sentence length: ', len(toks_cs['tokens'][0]))\n",
    "print(toks_cs['tokens'][0])\n",
    "print(toks_cs['ids'][0])\n",
    "update_stats('ChordSymbolTokenizer', toks_cs)\n",
    "print_stats('ChordSymbolTokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MelodyPitchTokenizer_m21\n",
      "len(melodyPitchTokenizer.vocab):  184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Melody Files: 100%|██████████| 650/650 [00:32<00:00, 19.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example sentence length:  196\n",
      "['bar', 'position_0x00', 'P:69', 'position_3x00', 'P:64', 'bar', 'position_0x00', 'P:71', 'position_0x75', 'P:71', 'position_1x00', 'P:71', 'position_3x00', 'P:64', 'bar', 'position_0x00', 'P:69', 'position_1x00', 'P:71', 'position_2x00', 'P:69', 'position_3x00', 'P:64', 'bar', 'position_0x00', 'P:71', 'position_3x00', 'P:69', 'bar', 'position_0x00', 'P:66', 'position_1x00', 'P:67', 'position_1x50', 'P:64', 'position_2x00', 'P:64', 'bar', 'position_0x00', 'P:66', 'position_1x00', 'P:67', 'position_1x50', 'P:64', 'position_2x00', 'P:64', 'position_3x50', 'P:66', 'bar', 'position_0x00', 'P:59', 'position_1x00', 'P:62', 'position_2x00', 'P:64', 'position_3x00', 'P:67', 'bar', 'position_0x00', 'P:66', 'position_0x50', 'P:67', 'position_1x00', 'P:64', 'position_3x00', 'P:62', 'bar', 'position_0x00', 'P:63', 'position_1x00', 'P:66', 'position_2x00', 'P:68', 'position_3x00', 'P:73', 'bar', 'position_0x00', 'P:71', 'position_0x50', 'P:73', 'position_1x00', 'P:71', 'position_3x00', 'P:71', 'bar', 'position_0x00', 'P:74', 'position_3x00', 'P:69', 'bar', 'position_0x00', 'P:72', 'position_3x00', 'P:71', 'bar', 'position_0x00', 'P:74', 'position_1x00', 'P:74', 'position_2x00', 'P:74', 'position_3x00', 'P:69', 'bar', 'position_0x00', 'P:72', 'position_1x00', 'P:72', 'position_3x00', 'P:67', 'bar', 'position_0x00', 'P:71', 'position_3x00', 'P:67', 'bar', 'position_0x00', 'P:69', 'position_3x00', 'P:67', 'bar', 'position_0x00', 'P:71', 'position_1x00', 'P:69', 'position_2x00', 'P:67', 'position_3x00', 'P:66', 'bar', 'position_0x00', 'P:64', 'position_1x00', 'P:66', 'position_3x00', 'P:62', 'bar', 'position_0x00', 'P:69', 'position_3x00', 'P:64', 'bar', 'position_0x00', 'P:71', 'position_0x75', 'P:71', 'position_1x00', 'P:71', 'position_3x00', 'P:69', 'bar', 'position_0x00', 'P:66', 'position_1x00', 'P:67', 'position_2x00', 'P:69', 'position_3x00', 'P:71', 'bar', 'position_0x00', 'P:74', 'position_3x00', 'P:71', 'bar', 'position_0x00', 'P:74', 'position_1x00', 'P:73', 'position_2x00', 'P:72', 'position_3x00', 'P:64', 'bar', 'position_0x00', 'P:74', 'position_0x50', 'P:73', 'position_1x00', 'P:72', 'position_3x00', 'P:71', 'bar', 'position_0x00', 'P:69', 'position_1x00', 'P:71', 'position_2x00', 'P:67', 'position_3x00', 'P:69', 'bar', 'position_0x00', 'P:67', 'position_3x00', 'Rest']\n",
      "[5, 94, 54, 121, 49, 5, 94, 56, 101, 56, 103, 56, 121, 49, 5, 94, 54, 103, 56, 112, 54, 121, 49, 5, 94, 56, 121, 54, 5, 94, 51, 103, 52, 108, 49, 112, 49, 5, 94, 51, 103, 52, 108, 49, 112, 49, 126, 51, 5, 94, 44, 103, 47, 112, 49, 121, 52, 5, 94, 51, 99, 52, 103, 49, 121, 47, 5, 94, 48, 103, 51, 112, 53, 121, 58, 5, 94, 56, 99, 58, 103, 56, 121, 56, 5, 94, 59, 121, 54, 5, 94, 57, 121, 56, 5, 94, 59, 103, 59, 112, 59, 121, 54, 5, 94, 57, 103, 57, 121, 52, 5, 94, 56, 121, 52, 5, 94, 54, 121, 52, 5, 94, 56, 103, 54, 112, 52, 121, 51, 5, 94, 49, 103, 51, 121, 47, 5, 94, 54, 121, 49, 5, 94, 56, 101, 56, 103, 56, 121, 54, 5, 94, 51, 103, 52, 112, 54, 121, 56, 5, 94, 59, 121, 56, 5, 94, 59, 103, 58, 112, 57, 121, 49, 5, 94, 59, 99, 58, 103, 57, 121, 56, 5, 94, 54, 103, 56, 112, 52, 121, 54, 5, 94, 52, 121, 4]\n",
      "vocab_size:  184\n",
      "mean len:  241.8323076923077\n",
      "std len:  88.73966003938332\n",
      "mean cr:  0.11353269972158636\n",
      "std cr:  0.02323730549065121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('MelodyPitchTokenizer_m21')\n",
    "melodyPitchTokenizer = MelodyPitchTokenizer(min_pitch=21, max_pitch=108) #default range, need to adjust\n",
    "print('len(melodyPitchTokenizer.vocab): ', len(melodyPitchTokenizer.vocab))\n",
    "initialize_stats('MelodyPitchTokenizer', melodyPitchTokenizer)\n",
    "toks_cs = melodyPitchTokenizer(data_files)\n",
    "print('example sentence length: ', len(toks_cs['tokens'][0]))\n",
    "print(toks_cs['tokens'][0])\n",
    "print(toks_cs['ids'][0])\n",
    "update_stats('MelodyPitchTokenizer', toks_cs)\n",
    "print_stats('MelodyPitchTokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print stats\n",
    "tokenizers = ['ChordSymbolTokenizer', 'MelodyPitchTokenizer'\n",
    "              ]\n",
    "\n",
    "results_path = 'vocab_stats_hk_m21.csv' #for hook theory\n",
    "\n",
    "result_fields = ['Tokenizer_m21', 'vocab_size'] + list( stats['ChordSymbolTokenizer'].keys() )[3:]\n",
    "\n",
    "with open( results_path, 'w' ) as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow( result_fields )\n",
    "\n",
    "for tok in tokenizers:\n",
    "    with open( results_path, 'a' ) as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow( [tok] + [stats[tok]['vocab_size']] + list( stats[tok].values() )[3:] )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "midi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
