{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import zlib\n",
    "import numpy as np\n",
    "from harmony_tokenizers_m21 import ChordSymbolTokenizer, RootTypeTokenizer, \\\n",
    "    PitchClassTokenizer, RootPCTokenizer, GCTRootPCTokenizer, \\\n",
    "    GCTSymbolTokenizer, GCTRootTypeTokenizer, MelodyPitchTokenizer, \\\n",
    "    MergedMelHarmTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files from Hook Theory dataset: 650\n"
     ]
    }
   ],
   "source": [
    "# root_dir = '/media/datadisk/datasets/hooktheory_xmls'\n",
    "root_dir = 'data/gjt_melodies/Library_melodies/'\n",
    "data_files = []\n",
    "\n",
    "# Walk through all subdirectories and files\n",
    "for dirpath, _, filenames in os.walk(root_dir):\n",
    "    for file in filenames:\n",
    "        if file.endswith('.xml') or file.endswith('.mxl'):\n",
    "            full_path = os.path.join(dirpath, file)\n",
    "            data_files.append(full_path)\n",
    "\n",
    "print('Total files from Hook Theory dataset:', len(data_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare stats\n",
    "stats = {}\n",
    "\n",
    "def compute_compression_rate(array: np.ndarray, compression_method=zlib.compress) -> float:\n",
    "    \"\"\"\n",
    "    Compute the compression rate of a NumPy array.\n",
    "\n",
    "    Parameters:\n",
    "        array (np.ndarray): The NumPy array to compress.\n",
    "        compression_method (callable): The compression method to use. \n",
    "                                       Default is `zlib.compress`.\n",
    "\n",
    "    Returns:\n",
    "        float: The compression rate (compressed size / original size).\n",
    "    \"\"\"\n",
    "    # Convert the array to bytes\n",
    "    array_bytes = array.tobytes()\n",
    "    \n",
    "    # Compress the byte representation\n",
    "    compressed_bytes = compression_method(array_bytes)\n",
    "    \n",
    "    # Compute sizes\n",
    "    original_size = len(array_bytes)\n",
    "    compressed_size = len(compressed_bytes)\n",
    "    \n",
    "    # Calculate compression rate\n",
    "    compression_rate = compressed_size / original_size\n",
    "\n",
    "    return compression_rate\n",
    "\n",
    "def initialize_stats(key, tokenizer):\n",
    "    stats[key] = {\n",
    "        'vocab_size': len(tokenizer.vocab),\n",
    "        'seq_lens': [],\n",
    "        'compression_rates': []\n",
    "    }\n",
    "# end initialize_stats\n",
    "\n",
    "def update_stats(key, toks):\n",
    "    for t in toks['ids']:\n",
    "        stats[key]['seq_lens'].append( len(t) )\n",
    "        stats[key]['compression_rates'].append( compute_compression_rate(np.array(t)) )\n",
    "    stats[key]['mean_len'] = np.mean(stats[key]['seq_lens'])\n",
    "    stats[key]['std_len'] = np.std(stats[key]['seq_lens'])\n",
    "    stats[key]['mean_compression'] = np.mean(stats[key]['compression_rates'])\n",
    "    stats[key]['std_compression'] = np.std(stats[key]['compression_rates'])\n",
    "# end update_stats\n",
    "\n",
    "def print_stats(key):\n",
    "    print('vocab_size: ', stats[key]['vocab_size'])\n",
    "    print('mean len: ', stats[key]['mean_len'])\n",
    "    print('std len: ', stats[key]['std_len'])\n",
    "    print('mean cr: ', stats[key]['mean_compression'])\n",
    "    print('std cr: ', stats[key]['std_compression'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChordSymbolTokenizer_m21\n",
      "len(chordSymbolTokenizer.vocab):  456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files:   0%|          | 0/650 [00:00<?, ?it/s]C:\\Users\\dimak\\AppData\\Roaming\\Python\\Python311\\site-packages\\music21\\stream\\base.py:3689: Music21DeprecationWarning: .flat is deprecated.  Call .flatten() instead\n",
      "  return self.iter().getElementsByClass(classFilterList)\n",
      "Processing Files: 100%|██████████| 650/650 [00:35<00:00, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example sentence length:  58\n",
      "['<h>', '<bar>', 'position_0x00', 'F:min7', '<bar>', 'position_0x00', 'G:min7', '<bar>', 'position_0x00', 'G#:maj7', 'position_1x50', 'G:min7', '<bar>', 'position_0x00', 'F:min7', '<bar>', 'position_0x00', 'F:min7', '<bar>', 'position_0x00', 'G:min7', '<bar>', 'position_0x00', 'G#:maj7', 'position_1x50', 'G:min7', '<bar>', 'position_0x00', 'F:min7', '<bar>', 'position_0x00', 'D#:maj', '<bar>', 'position_0x00', 'D#:maj', '<bar>', 'position_0x00', 'C#:maj', 'position_1x50', 'D#:maj', '<bar>', 'position_0x00', 'F:min7', '<bar>', 'position_0x00', 'D#:maj', '<bar>', 'position_0x00', 'D#:maj', '<bar>', 'position_0x00', 'C#:maj', 'position_1x50', 'D#:maj', '<bar>', 'position_0x00', 'F:min7', '</s>']\n",
      "[7, 6, 8, 261, 6, 8, 319, 6, 8, 347, 20, 319, 6, 8, 261, 6, 8, 261, 6, 8, 319, 6, 8, 347, 20, 319, 6, 8, 261, 6, 8, 195, 6, 8, 195, 6, 8, 137, 20, 195, 6, 8, 261, 6, 8, 195, 6, 8, 195, 6, 8, 137, 20, 195, 6, 8, 261, 3]\n",
      "vocab_size:  456\n",
      "mean len:  105.60307692307693\n",
      "std len:  34.296615528159485\n",
      "mean cr:  0.21106668178714563\n",
      "std cr:  0.04754235687390645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('ChordSymbolTokenizer_m21')\n",
    "chordSymbolTokenizer = ChordSymbolTokenizer()\n",
    "print('len(chordSymbolTokenizer.vocab): ', len(chordSymbolTokenizer.vocab))\n",
    "initialize_stats('ChordSymbolTokenizer', chordSymbolTokenizer)\n",
    "toks_cs = chordSymbolTokenizer(data_files)\n",
    "print('example sentence length: ', len(toks_cs['tokens'][0]))\n",
    "print(toks_cs['tokens'][0])\n",
    "print(toks_cs['ids'][0])\n",
    "update_stats('ChordSymbolTokenizer', toks_cs)\n",
    "print_stats('ChordSymbolTokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RootTypeTokenizer\n",
      "len(rootTypeTokenizer.vocab):  149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files: 100%|██████████| 650/650 [01:03<00:00, 10.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example sentence length:  78\n",
      "['<h>', '<bar>', 'position_0x00', 'F', 'min7', '<bar>', 'position_0x00', 'G', 'min7', '<bar>', 'position_0x00', 'G#', 'maj7', 'position_1x50', 'G', 'min7', '<bar>', 'position_0x00', 'F', 'min7', '<bar>', 'position_0x00', 'F', 'min7', '<bar>', 'position_0x00', 'G', 'min7', '<bar>', 'position_0x00', 'G#', 'maj7', 'position_1x50', 'G', 'min7', '<bar>', 'position_0x00', 'F', 'min7', '<bar>', 'position_0x00', 'D#', 'maj', '<bar>', 'position_0x00', 'D#', 'maj', '<bar>', 'position_0x00', 'C#', 'maj', 'position_1x50', 'D#', 'maj', '<bar>', 'position_0x00', 'F', 'min7', '<bar>', 'position_0x00', 'D#', 'maj', '<bar>', 'position_0x00', 'D#', 'maj', '<bar>', 'position_0x00', 'C#', 'maj', 'position_1x50', 'D#', 'maj', '<bar>', 'position_0x00', 'F', 'min7', '</s>']\n",
      "[7, 6, 8, 113, 128, 6, 8, 115, 128, 6, 8, 116, 127, 20, 115, 128, 6, 8, 113, 128, 6, 8, 113, 128, 6, 8, 115, 128, 6, 8, 116, 127, 20, 115, 128, 6, 8, 113, 128, 6, 8, 111, 120, 6, 8, 111, 120, 6, 8, 109, 120, 20, 111, 120, 6, 8, 113, 128, 6, 8, 111, 120, 6, 8, 111, 120, 6, 8, 109, 120, 20, 111, 120, 6, 8, 113, 128, 3]\n",
      "vocab_size:  149\n",
      "mean len:  143.68769230769232\n",
      "std len:  47.76576826296714\n",
      "mean cr:  0.1801121801680095\n",
      "std cr:  0.04102870244515891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('RootTypeTokenizer')\n",
    "rootTypeTokenizer = RootTypeTokenizer()\n",
    "print('len(rootTypeTokenizer.vocab): ', len(rootTypeTokenizer.vocab))\n",
    "initialize_stats('RootTypeTokenizer', rootTypeTokenizer)\n",
    "toks_rt = rootTypeTokenizer(data_files)\n",
    "print('example sentence length: ', len(toks_rt['tokens'][0]))\n",
    "print(toks_rt['tokens'][0])\n",
    "print(toks_rt['ids'][0])\n",
    "update_stats('RootTypeTokenizer', toks_rt)\n",
    "print_stats('RootTypeTokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PitchClassTokenizer\n",
      "len(pitchClassTokenizer.vocab):  120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files: 100%|██████████| 650/650 [00:46<00:00, 13.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example sentence length:  110\n",
      "['<h>', '<bar>', 'position_0x00', 'chord_pc_5', 'chord_pc_8', 'chord_pc_0', 'chord_pc_3', '<bar>', 'position_0x00', 'chord_pc_7', 'chord_pc_10', 'chord_pc_2', 'chord_pc_5', '<bar>', 'position_0x00', 'chord_pc_8', 'chord_pc_0', 'chord_pc_3', 'chord_pc_7', 'position_1x50', 'chord_pc_7', 'chord_pc_10', 'chord_pc_2', 'chord_pc_5', '<bar>', 'position_0x00', 'chord_pc_5', 'chord_pc_8', 'chord_pc_0', 'chord_pc_3', '<bar>', 'position_0x00', 'chord_pc_5', 'chord_pc_8', 'chord_pc_0', 'chord_pc_3', '<bar>', 'position_0x00', 'chord_pc_7', 'chord_pc_10', 'chord_pc_2', 'chord_pc_5', '<bar>', 'position_0x00', 'chord_pc_8', 'chord_pc_0', 'chord_pc_3', 'chord_pc_7', 'position_1x50', 'chord_pc_7', 'chord_pc_10', 'chord_pc_2', 'chord_pc_5', '<bar>', 'position_0x00', 'chord_pc_5', 'chord_pc_8', 'chord_pc_0', 'chord_pc_3', '<bar>', 'position_0x00', 'chord_pc_3', 'chord_pc_7', 'chord_pc_10', '<bar>', 'position_0x00', 'chord_pc_3', 'chord_pc_7', 'chord_pc_10', '<bar>', 'position_0x00', 'chord_pc_1', 'chord_pc_5', 'chord_pc_8', 'position_1x50', 'chord_pc_3', 'chord_pc_7', 'chord_pc_10', '<bar>', 'position_0x00', 'chord_pc_5', 'chord_pc_8', 'chord_pc_0', 'chord_pc_3', '<bar>', 'position_0x00', 'chord_pc_3', 'chord_pc_7', 'chord_pc_10', '<bar>', 'position_0x00', 'chord_pc_3', 'chord_pc_7', 'chord_pc_10', '<bar>', 'position_0x00', 'chord_pc_1', 'chord_pc_5', 'chord_pc_8', 'position_1x50', 'chord_pc_3', 'chord_pc_7', 'chord_pc_10', '<bar>', 'position_0x00', 'chord_pc_5', 'chord_pc_8', 'chord_pc_0', 'chord_pc_3', '</s>']\n",
      "[7, 6, 8, 113, 116, 108, 111, 6, 8, 115, 118, 110, 113, 6, 8, 116, 108, 111, 115, 20, 115, 118, 110, 113, 6, 8, 113, 116, 108, 111, 6, 8, 113, 116, 108, 111, 6, 8, 115, 118, 110, 113, 6, 8, 116, 108, 111, 115, 20, 115, 118, 110, 113, 6, 8, 113, 116, 108, 111, 6, 8, 111, 115, 118, 6, 8, 111, 115, 118, 6, 8, 109, 113, 116, 20, 111, 115, 118, 6, 8, 113, 116, 108, 111, 6, 8, 111, 115, 118, 6, 8, 111, 115, 118, 6, 8, 109, 113, 116, 20, 111, 115, 118, 6, 8, 113, 116, 108, 111, 3]\n",
      "vocab_size:  120\n",
      "mean len:  223.54461538461538\n",
      "std len:  76.19775088699592\n",
      "mean cr:  0.1489367003032588\n",
      "std cr:  0.035578199570863465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('PitchClassTokenizer')\n",
    "pitchClassTokenizer = PitchClassTokenizer()\n",
    "print('len(pitchClassTokenizer.vocab): ', len(pitchClassTokenizer.vocab))\n",
    "initialize_stats('PitchClassTokenizer', pitchClassTokenizer)\n",
    "toks_pc = pitchClassTokenizer(data_files)\n",
    "print('example sentence length: ', len(toks_pc['tokens'][0]))\n",
    "print(toks_pc['tokens'][0])\n",
    "print(toks_pc['ids'][0])\n",
    "update_stats('PitchClassTokenizer', toks_pc)\n",
    "print_stats('PitchClassTokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RootPCTokenizer\n",
      "len(rootPCTokenizer.vocab):  132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files: 100%|██████████| 650/650 [01:06<00:00,  9.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example sentence length:  110\n",
      "['<h>', '<bar>', 'position_0x00', 'chord_root_5', 'chord_pc_8', 'chord_pc_0', 'chord_pc_3', '<bar>', 'position_0x00', 'chord_root_7', 'chord_pc_10', 'chord_pc_2', 'chord_pc_5', '<bar>', 'position_0x00', 'chord_root_8', 'chord_pc_0', 'chord_pc_3', 'chord_pc_7', 'position_1x50', 'chord_root_7', 'chord_pc_10', 'chord_pc_2', 'chord_pc_5', '<bar>', 'position_0x00', 'chord_root_5', 'chord_pc_8', 'chord_pc_0', 'chord_pc_3', '<bar>', 'position_0x00', 'chord_root_5', 'chord_pc_8', 'chord_pc_0', 'chord_pc_3', '<bar>', 'position_0x00', 'chord_root_7', 'chord_pc_10', 'chord_pc_2', 'chord_pc_5', '<bar>', 'position_0x00', 'chord_root_8', 'chord_pc_0', 'chord_pc_3', 'chord_pc_7', 'position_1x50', 'chord_root_7', 'chord_pc_10', 'chord_pc_2', 'chord_pc_5', '<bar>', 'position_0x00', 'chord_root_5', 'chord_pc_8', 'chord_pc_0', 'chord_pc_3', '<bar>', 'position_0x00', 'chord_root_3', 'chord_pc_7', 'chord_pc_10', '<bar>', 'position_0x00', 'chord_root_3', 'chord_pc_7', 'chord_pc_10', '<bar>', 'position_0x00', 'chord_root_1', 'chord_pc_5', 'chord_pc_8', 'position_1x50', 'chord_root_3', 'chord_pc_7', 'chord_pc_10', '<bar>', 'position_0x00', 'chord_root_5', 'chord_pc_8', 'chord_pc_0', 'chord_pc_3', '<bar>', 'position_0x00', 'chord_root_3', 'chord_pc_7', 'chord_pc_10', '<bar>', 'position_0x00', 'chord_root_3', 'chord_pc_7', 'chord_pc_10', '<bar>', 'position_0x00', 'chord_root_1', 'chord_pc_5', 'chord_pc_8', 'position_1x50', 'chord_root_3', 'chord_pc_7', 'chord_pc_10', '<bar>', 'position_0x00', 'chord_root_5', 'chord_pc_8', 'chord_pc_0', 'chord_pc_3', '</s>']\n",
      "[7, 6, 8, 113, 128, 120, 123, 6, 8, 115, 130, 122, 125, 6, 8, 116, 120, 123, 127, 20, 115, 130, 122, 125, 6, 8, 113, 128, 120, 123, 6, 8, 113, 128, 120, 123, 6, 8, 115, 130, 122, 125, 6, 8, 116, 120, 123, 127, 20, 115, 130, 122, 125, 6, 8, 113, 128, 120, 123, 6, 8, 111, 127, 130, 6, 8, 111, 127, 130, 6, 8, 109, 125, 128, 20, 111, 127, 130, 6, 8, 113, 128, 120, 123, 6, 8, 111, 127, 130, 6, 8, 111, 127, 130, 6, 8, 109, 125, 128, 20, 111, 127, 130, 6, 8, 113, 128, 120, 123, 3]\n",
      "vocab_size:  132\n",
      "mean len:  223.54461538461538\n",
      "std len:  76.19775088699592\n",
      "mean cr:  0.16243596618924913\n",
      "std cr:  0.039573170709361595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('RootPCTokenizer')\n",
    "rootPCTokenizer = RootPCTokenizer()\n",
    "print('len(rootPCTokenizer.vocab): ', len(rootPCTokenizer.vocab))\n",
    "initialize_stats('RootPCTokenizer', rootPCTokenizer)\n",
    "toks_rpc = rootPCTokenizer(data_files)\n",
    "print('example sentence length: ', len(toks_rpc['tokens'][0]))\n",
    "print(toks_rpc['tokens'][0])\n",
    "print(toks_rpc['ids'][0])\n",
    "update_stats('RootPCTokenizer', toks_rpc)\n",
    "print_stats('RootPCTokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCTRootPCTokenizer\n",
      "len(gctRootPCTokenizer.vocab):  132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files: 100%|██████████| 650/650 [01:21<00:00,  7.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example sentence length:  110\n",
      "['<h>', '<bar>', 'position_0x00', 'chord_root_5', 'chord_pc_8', 'chord_pc_0', 'chord_pc_3', '<bar>', 'position_0x00', 'chord_root_10', 'chord_pc_2', 'chord_pc_5', 'chord_pc_7', '<bar>', 'position_0x00', 'chord_root_0', 'chord_pc_3', 'chord_pc_7', 'chord_pc_8', 'position_1x50', 'chord_root_10', 'chord_pc_2', 'chord_pc_5', 'chord_pc_7', '<bar>', 'position_0x00', 'chord_root_5', 'chord_pc_8', 'chord_pc_0', 'chord_pc_3', '<bar>', 'position_0x00', 'chord_root_5', 'chord_pc_8', 'chord_pc_0', 'chord_pc_3', '<bar>', 'position_0x00', 'chord_root_10', 'chord_pc_2', 'chord_pc_5', 'chord_pc_7', '<bar>', 'position_0x00', 'chord_root_0', 'chord_pc_3', 'chord_pc_7', 'chord_pc_8', 'position_1x50', 'chord_root_10', 'chord_pc_2', 'chord_pc_5', 'chord_pc_7', '<bar>', 'position_0x00', 'chord_root_5', 'chord_pc_8', 'chord_pc_0', 'chord_pc_3', '<bar>', 'position_0x00', 'chord_root_3', 'chord_pc_7', 'chord_pc_10', '<bar>', 'position_0x00', 'chord_root_3', 'chord_pc_7', 'chord_pc_10', '<bar>', 'position_0x00', 'chord_root_1', 'chord_pc_5', 'chord_pc_8', 'position_1x50', 'chord_root_3', 'chord_pc_7', 'chord_pc_10', '<bar>', 'position_0x00', 'chord_root_5', 'chord_pc_8', 'chord_pc_0', 'chord_pc_3', '<bar>', 'position_0x00', 'chord_root_3', 'chord_pc_7', 'chord_pc_10', '<bar>', 'position_0x00', 'chord_root_3', 'chord_pc_7', 'chord_pc_10', '<bar>', 'position_0x00', 'chord_root_1', 'chord_pc_5', 'chord_pc_8', 'position_1x50', 'chord_root_3', 'chord_pc_7', 'chord_pc_10', '<bar>', 'position_0x00', 'chord_root_5', 'chord_pc_8', 'chord_pc_0', 'chord_pc_3', '</s>']\n",
      "[7, 6, 8, 113, 128, 120, 123, 6, 8, 118, 122, 125, 127, 6, 8, 108, 123, 127, 128, 20, 118, 122, 125, 127, 6, 8, 113, 128, 120, 123, 6, 8, 113, 128, 120, 123, 6, 8, 118, 122, 125, 127, 6, 8, 108, 123, 127, 128, 20, 118, 122, 125, 127, 6, 8, 113, 128, 120, 123, 6, 8, 111, 127, 130, 6, 8, 111, 127, 130, 6, 8, 109, 125, 128, 20, 111, 127, 130, 6, 8, 113, 128, 120, 123, 6, 8, 111, 127, 130, 6, 8, 111, 127, 130, 6, 8, 109, 125, 128, 20, 111, 127, 130, 6, 8, 113, 128, 120, 123, 3]\n",
      "vocab_size:  132\n",
      "mean len:  223.54461538461538\n",
      "std len:  76.19775088699592\n",
      "mean cr:  0.15878654035348186\n",
      "std cr:  0.03821975318519985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('GCTRootPCTokenizer')\n",
    "gctRootPCTokenizer = GCTRootPCTokenizer()\n",
    "print('len(gctRootPCTokenizer.vocab): ', len(gctRootPCTokenizer.vocab))\n",
    "initialize_stats('GCTRootPCTokenizer', gctRootPCTokenizer)\n",
    "toks_gct_rpc = gctRootPCTokenizer(data_files)\n",
    "print('example sentence length: ', len(toks_gct_rpc['tokens'][0]))\n",
    "print(toks_gct_rpc['tokens'][0])\n",
    "print(toks_gct_rpc['ids'][0])\n",
    "update_stats('GCTRootPCTokenizer', toks_gct_rpc)\n",
    "print_stats('GCTRootPCTokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCTSymbolTokenizer\n",
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files: 100%|██████████| 650/650 [01:18<00:00,  8.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(gctSymbolTokenizer.vocab):  336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files: 100%|██████████| 650/650 [01:00<00:00, 10.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example sentence length:  58\n",
      "['<h>', '<bar>', 'position_0x00', '[ 5  0  3  7 10]', '<bar>', 'position_0x00', '[10  0  4  7  9]', '<bar>', 'position_0x00', '[0 0 3 7 8]', 'position_1x50', '[10  0  4  7  9]', '<bar>', 'position_0x00', '[ 5  0  3  7 10]', '<bar>', 'position_0x00', '[ 5  0  3  7 10]', '<bar>', 'position_0x00', '[10  0  4  7  9]', '<bar>', 'position_0x00', '[0 0 3 7 8]', 'position_1x50', '[10  0  4  7  9]', '<bar>', 'position_0x00', '[ 5  0  3  7 10]', '<bar>', 'position_0x00', '[3 0 4 7]', '<bar>', 'position_0x00', '[3 0 4 7]', '<bar>', 'position_0x00', '[1 0 4 7]', 'position_1x50', '[3 0 4 7]', '<bar>', 'position_0x00', '[ 5  0  3  7 10]', '<bar>', 'position_0x00', '[3 0 4 7]', '<bar>', 'position_0x00', '[3 0 4 7]', '<bar>', 'position_0x00', '[1 0 4 7]', 'position_1x50', '[3 0 4 7]', '<bar>', 'position_0x00', '[ 5  0  3  7 10]', '</s>']\n",
      "[7, 6, 8, 108, 6, 8, 109, 6, 8, 110, 20, 109, 6, 8, 108, 6, 8, 108, 6, 8, 109, 6, 8, 110, 20, 109, 6, 8, 108, 6, 8, 111, 6, 8, 111, 6, 8, 112, 20, 111, 6, 8, 108, 6, 8, 111, 6, 8, 111, 6, 8, 112, 20, 111, 6, 8, 108, 3]\n",
      "vocab_size:  336\n",
      "mean len:  105.60307692307693\n",
      "std len:  34.296615528159485\n",
      "mean cr:  0.19889406687956152\n",
      "std cr:  0.0460592713715295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('GCTSymbolTokenizer')\n",
    "gctSymbolTokenizer = GCTSymbolTokenizer()\n",
    "print('training')\n",
    "gctSymbolTokenizer.fit( data_files )\n",
    "print('len(gctSymbolTokenizer.vocab): ', len(gctSymbolTokenizer.vocab))\n",
    "initialize_stats('GCTSymbolTokenizer', gctSymbolTokenizer)\n",
    "toks_gct_symb = gctSymbolTokenizer(data_files)\n",
    "print('example sentence length: ', len(toks_gct_symb['tokens'][0]))\n",
    "print(toks_gct_symb['tokens'][0])\n",
    "print(toks_gct_symb['ids'][0])\n",
    "update_stats('GCTSymbolTokenizer', toks_gct_symb)\n",
    "print_stats('GCTSymbolTokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCTRootTypeTokenizer\n",
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files: 100%|██████████| 650/650 [01:15<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(gctRootTypeTokenizer.vocab):  165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files: 100%|██████████| 650/650 [01:30<00:00,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example sentence length:  78\n",
      "['<h>', '<bar>', 'position_0x00', 'chord_root_5', '[ 0  3  7 10]', '<bar>', 'position_0x00', 'chord_root_10', '[0 4 7 9]', '<bar>', 'position_0x00', 'chord_root_0', '[0 3 7 8]', 'position_1x50', 'chord_root_10', '[0 4 7 9]', '<bar>', 'position_0x00', 'chord_root_5', '[ 0  3  7 10]', '<bar>', 'position_0x00', 'chord_root_5', '[ 0  3  7 10]', '<bar>', 'position_0x00', 'chord_root_10', '[0 4 7 9]', '<bar>', 'position_0x00', 'chord_root_0', '[0 3 7 8]', 'position_1x50', 'chord_root_10', '[0 4 7 9]', '<bar>', 'position_0x00', 'chord_root_5', '[ 0  3  7 10]', '<bar>', 'position_0x00', 'chord_root_3', '[0 4 7]', '<bar>', 'position_0x00', 'chord_root_3', '[0 4 7]', '<bar>', 'position_0x00', 'chord_root_1', '[0 4 7]', 'position_1x50', 'chord_root_3', '[0 4 7]', '<bar>', 'position_0x00', 'chord_root_5', '[ 0  3  7 10]', '<bar>', 'position_0x00', 'chord_root_3', '[0 4 7]', '<bar>', 'position_0x00', 'chord_root_3', '[0 4 7]', '<bar>', 'position_0x00', 'chord_root_1', '[0 4 7]', 'position_1x50', 'chord_root_3', '[0 4 7]', '<bar>', 'position_0x00', 'chord_root_5', '[ 0  3  7 10]', '</s>']\n",
      "[7, 6, 8, 113, 120, 6, 8, 118, 121, 6, 8, 108, 122, 20, 118, 121, 6, 8, 113, 120, 6, 8, 113, 120, 6, 8, 118, 121, 6, 8, 108, 122, 20, 118, 121, 6, 8, 113, 120, 6, 8, 111, 123, 6, 8, 111, 123, 6, 8, 109, 123, 20, 111, 123, 6, 8, 113, 120, 6, 8, 111, 123, 6, 8, 111, 123, 6, 8, 109, 123, 20, 111, 123, 6, 8, 113, 120, 3]\n",
      "vocab_size:  165\n",
      "mean len:  143.68769230769232\n",
      "std len:  47.76576826296714\n",
      "mean cr:  0.17883608702340512\n",
      "std cr:  0.041108852424086705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('GCTRootTypeTokenizer')\n",
    "gctRootTypeTokenizer = GCTRootTypeTokenizer()\n",
    "print('training')\n",
    "gctRootTypeTokenizer.fit( data_files )\n",
    "print('len(gctRootTypeTokenizer.vocab): ', len(gctRootTypeTokenizer.vocab))\n",
    "initialize_stats('GCTRootTypeTokenizer', gctRootTypeTokenizer)\n",
    "toks_gct_rt = gctRootTypeTokenizer(data_files)\n",
    "print('example sentence length: ', len(toks_gct_rt['tokens'][0]))\n",
    "print(toks_gct_rt['tokens'][0])\n",
    "print(toks_gct_rt['ids'][0])\n",
    "update_stats('GCTRootTypeTokenizer', toks_gct_rt)\n",
    "print_stats('GCTRootTypeTokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MelodyPitchTokenizer_m21\n",
      "len(melodyPitchTokenizer.vocab):  195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Melody Files: 100%|██████████| 650/650 [00:32<00:00, 19.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example sentence length:  78\n",
      "['<s>', '<bar>', 'position_0x00', 'P:65', 'position_1x00', 'P:72', 'position_2x50', 'P:68', '<bar>', 'position_0x00', 'P:70', '<bar>', 'position_0x00', 'P:68', 'position_1x50', 'P:70', '<bar>', 'position_0x00', 'P:65', 'position_2x00', '<rest>', 'position_2x50', 'P:60', '<bar>', 'position_0x00', 'P:65', 'position_1x00', 'P:72', 'position_2x50', 'P:68', '<bar>', 'position_0x00', 'P:70', '<bar>', 'position_0x00', 'P:68', 'position_1x50', 'P:70', '<bar>', 'position_0x00', 'P:65', '<bar>', 'position_0x00', 'P:63', 'position_1x00', 'P:63', 'position_2x00', 'P:67', '<bar>', 'position_0x00', 'P:63', '<bar>', 'position_0x00', 'P:61', 'position_1x50', 'P:63', '<bar>', 'position_0x00', 'P:65', '<bar>', 'position_0x00', 'P:63', 'position_1x00', 'P:63', 'position_2x00', 'P:67', '<bar>', 'position_0x00', 'P:63', '<bar>', 'position_0x00', 'P:61', 'position_1x50', 'P:68', '<bar>', 'position_0x00', 'P:65', '</s>']\n",
      "[2, 6, 95, 51, 103, 58, 115, 54, 6, 95, 56, 6, 95, 54, 107, 56, 6, 95, 51, 111, 4, 115, 46, 6, 95, 51, 103, 58, 115, 54, 6, 95, 56, 6, 95, 54, 107, 56, 6, 95, 51, 6, 95, 49, 103, 49, 111, 53, 6, 95, 49, 6, 95, 47, 107, 49, 6, 95, 51, 6, 95, 49, 103, 49, 111, 53, 6, 95, 49, 6, 95, 47, 107, 54, 6, 95, 51, 3]\n",
      "vocab_size:  195\n",
      "mean len:  243.8323076923077\n",
      "std len:  88.73966003938332\n",
      "mean cr:  0.19536349249049545\n",
      "std cr:  0.04173949472228127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('MelodyPitchTokenizer_m21')\n",
    "melodyPitchTokenizer = MelodyPitchTokenizer(min_pitch=21, max_pitch=108) #default range, need to adjust\n",
    "print('len(melodyPitchTokenizer.vocab): ', len(melodyPitchTokenizer.vocab))\n",
    "initialize_stats('MelodyPitchTokenizer', melodyPitchTokenizer)\n",
    "toks_cs = melodyPitchTokenizer(data_files)\n",
    "print('example sentence length: ', len(toks_cs['tokens'][0]))\n",
    "print(toks_cs['tokens'][0])\n",
    "print(toks_cs['ids'][0])\n",
    "update_stats('MelodyPitchTokenizer', toks_cs)\n",
    "print_stats('MelodyPitchTokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print stats\n",
    "tokenizers = ['ChordSymbolTokenizer', 'MelodyPitchTokenizer'\n",
    "              ]\n",
    "\n",
    "results_path = 'vocab_stats_hk_m21.csv' #for hook theory\n",
    "\n",
    "result_fields = ['Tokenizer_m21', 'vocab_size'] + list( stats['ChordSymbolTokenizer'].keys() )[3:]\n",
    "\n",
    "with open( results_path, 'w' ) as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow( result_fields )\n",
    "\n",
    "for tok in tokenizers:\n",
    "    with open( results_path, 'a' ) as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow( [tok] + [stats[tok]['vocab_size']] + list( stats[tok].values() )[3:] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging harmony vocab\n"
     ]
    }
   ],
   "source": [
    "m_chordSymbolTokenizer = MergedMelHarmTokenizer(melodyPitchTokenizer, chordSymbolTokenizer, verbose=1)\n",
    "#m_rootTypeTokenizer = MergedMelHarmTokenizer(melodyPitchTokenizer, rootTypeTokenizer)\n",
    "#m_pitchClassTokenizer = MergedMelHarmTokenizer(melodyPitchTokenizer, pitchClassTokenizer)\n",
    "#m_rootPCTokenizer = MergedMelHarmTokenizer(melodyPitchTokenizer, rootPCTokenizer)\n",
    "#m_gctRootPCTokenizer = MergedMelHarmTokenizer(melodyPitchTokenizer, gctRootPCTokenizer)\n",
    "#m_gctSymbolTokenizer = MergedMelHarmTokenizer(melodyPitchTokenizer, gctSymbolTokenizer)\n",
    "#m_gctRootTypeTokenizer = MergedMelHarmTokenizer(melodyPitchTokenizer, gctRootTypeTokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of combined vocab: 545\n",
      "Combined vocab: {'<unk>': 0, '<pad>': 1, '<s>': 2, '</s>': 3, '<rest>': 4, '<mask>': 5, '<bar>': 6, 'P:21': 7, 'P:22': 8, 'P:23': 9, 'P:24': 10, 'P:25': 11, 'P:26': 12, 'P:27': 13, 'P:28': 14, 'P:29': 15, 'P:30': 16, 'P:31': 17, 'P:32': 18, 'P:33': 19, 'P:34': 20, 'P:35': 21, 'P:36': 22, 'P:37': 23, 'P:38': 24, 'P:39': 25, 'P:40': 26, 'P:41': 27, 'P:42': 28, 'P:43': 29, 'P:44': 30, 'P:45': 31, 'P:46': 32, 'P:47': 33, 'P:48': 34, 'P:49': 35, 'P:50': 36, 'P:51': 37, 'P:52': 38, 'P:53': 39, 'P:54': 40, 'P:55': 41, 'P:56': 42, 'P:57': 43, 'P:58': 44, 'P:59': 45, 'P:60': 46, 'P:61': 47, 'P:62': 48, 'P:63': 49, 'P:64': 50, 'P:65': 51, 'P:66': 52, 'P:67': 53, 'P:68': 54, 'P:69': 55, 'P:70': 56, 'P:71': 57, 'P:72': 58, 'P:73': 59, 'P:74': 60, 'P:75': 61, 'P:76': 62, 'P:77': 63, 'P:78': 64, 'P:79': 65, 'P:80': 66, 'P:81': 67, 'P:82': 68, 'P:83': 69, 'P:84': 70, 'P:85': 71, 'P:86': 72, 'P:87': 73, 'P:88': 74, 'P:89': 75, 'P:90': 76, 'P:91': 77, 'P:92': 78, 'P:93': 79, 'P:94': 80, 'P:95': 81, 'P:96': 82, 'P:97': 83, 'P:98': 84, 'P:99': 85, 'P:100': 86, 'P:101': 87, 'P:102': 88, 'P:103': 89, 'P:104': 90, 'P:105': 91, 'P:106': 92, 'P:107': 93, 'P:108': 94, 'position_0x00': 95, 'position_0x16': 96, 'position_0x25': 97, 'position_0x33': 98, 'position_0x50': 99, 'position_0x66': 100, 'position_0x75': 101, 'position_0x83': 102, 'position_1x00': 103, 'position_1x16': 104, 'position_1x25': 105, 'position_1x33': 106, 'position_1x50': 107, 'position_1x66': 108, 'position_1x75': 109, 'position_1x83': 110, 'position_2x00': 111, 'position_2x16': 112, 'position_2x25': 113, 'position_2x33': 114, 'position_2x50': 115, 'position_2x66': 116, 'position_2x75': 117, 'position_2x83': 118, 'position_3x00': 119, 'position_3x16': 120, 'position_3x25': 121, 'position_3x33': 122, 'position_3x50': 123, 'position_3x66': 124, 'position_3x75': 125, 'position_3x83': 126, 'position_4x00': 127, 'position_4x16': 128, 'position_4x25': 129, 'position_4x33': 130, 'position_4x50': 131, 'position_4x66': 132, 'position_4x75': 133, 'position_4x83': 134, 'position_5x00': 135, 'position_5x16': 136, 'position_5x25': 137, 'position_5x33': 138, 'position_5x50': 139, 'position_5x66': 140, 'position_5x75': 141, 'position_5x83': 142, 'position_6x00': 143, 'position_6x16': 144, 'position_6x25': 145, 'position_6x33': 146, 'position_6x50': 147, 'position_6x66': 148, 'position_6x75': 149, 'position_6x83': 150, 'position_7x00': 151, 'position_7x16': 152, 'position_7x25': 153, 'position_7x33': 154, 'position_7x50': 155, 'position_7x66': 156, 'position_7x75': 157, 'position_7x83': 158, 'position_8x00': 159, 'position_8x16': 160, 'position_8x25': 161, 'position_8x33': 162, 'position_8x50': 163, 'position_8x66': 164, 'position_8x75': 165, 'position_8x83': 166, 'position_9x00': 167, 'position_9x16': 168, 'position_9x25': 169, 'position_9x33': 170, 'position_9x50': 171, 'position_9x66': 172, 'position_9x75': 173, 'position_9x83': 174, 'ts_1x4': 175, 'ts_1x8': 176, 'ts_2x4': 177, 'ts_3x4': 178, 'ts_3x8': 179, 'ts_4x4': 180, 'ts_5x4': 181, 'ts_5x8': 182, 'ts_6x4': 183, 'ts_7x4': 184, 'ts_7x8': 185, 'ts_8x4': 186, 'ts_9x4': 187, 'ts_9x8': 188, 'ts_10x4': 189, 'ts_11x8': 190, 'ts_13x8': 191, 'ts_15x8': 192, 'ts_17x8': 193, 'ts_19x8': 194, '<emp>': 195, '<h>': 196, 'C:maj': 197, 'C:min': 198, 'C:aug': 199, 'C:dim': 200, 'C:sus4': 201, 'C:sus2': 202, 'C:7': 203, 'C:maj7': 204, 'C:min7': 205, 'C:minmaj7': 206, 'C:maj6': 207, 'C:min6': 208, 'C:dim7': 209, 'C:hdim7': 210, 'C:maj9': 211, 'C:min9': 212, 'C:9': 213, 'C:min11': 214, 'C:11': 215, 'C:maj13': 216, 'C:min13': 217, 'C:13': 218, 'C:1': 219, 'C:5': 220, 'C:': 221, 'C:7(b9)': 222, 'C:7(#9)': 223, 'C:7(#11)': 224, 'C:7(b13)': 225, 'C#:maj': 226, 'C#:min': 227, 'C#:aug': 228, 'C#:dim': 229, 'C#:sus4': 230, 'C#:sus2': 231, 'C#:7': 232, 'C#:maj7': 233, 'C#:min7': 234, 'C#:minmaj7': 235, 'C#:maj6': 236, 'C#:min6': 237, 'C#:dim7': 238, 'C#:hdim7': 239, 'C#:maj9': 240, 'C#:min9': 241, 'C#:9': 242, 'C#:min11': 243, 'C#:11': 244, 'C#:maj13': 245, 'C#:min13': 246, 'C#:13': 247, 'C#:1': 248, 'C#:5': 249, 'C#:': 250, 'C#:7(b9)': 251, 'C#:7(#9)': 252, 'C#:7(#11)': 253, 'C#:7(b13)': 254, 'D:maj': 255, 'D:min': 256, 'D:aug': 257, 'D:dim': 258, 'D:sus4': 259, 'D:sus2': 260, 'D:7': 261, 'D:maj7': 262, 'D:min7': 263, 'D:minmaj7': 264, 'D:maj6': 265, 'D:min6': 266, 'D:dim7': 267, 'D:hdim7': 268, 'D:maj9': 269, 'D:min9': 270, 'D:9': 271, 'D:min11': 272, 'D:11': 273, 'D:maj13': 274, 'D:min13': 275, 'D:13': 276, 'D:1': 277, 'D:5': 278, 'D:': 279, 'D:7(b9)': 280, 'D:7(#9)': 281, 'D:7(#11)': 282, 'D:7(b13)': 283, 'D#:maj': 284, 'D#:min': 285, 'D#:aug': 286, 'D#:dim': 287, 'D#:sus4': 288, 'D#:sus2': 289, 'D#:7': 290, 'D#:maj7': 291, 'D#:min7': 292, 'D#:minmaj7': 293, 'D#:maj6': 294, 'D#:min6': 295, 'D#:dim7': 296, 'D#:hdim7': 297, 'D#:maj9': 298, 'D#:min9': 299, 'D#:9': 300, 'D#:min11': 301, 'D#:11': 302, 'D#:maj13': 303, 'D#:min13': 304, 'D#:13': 305, 'D#:1': 306, 'D#:5': 307, 'D#:': 308, 'D#:7(b9)': 309, 'D#:7(#9)': 310, 'D#:7(#11)': 311, 'D#:7(b13)': 312, 'E:maj': 313, 'E:min': 314, 'E:aug': 315, 'E:dim': 316, 'E:sus4': 317, 'E:sus2': 318, 'E:7': 319, 'E:maj7': 320, 'E:min7': 321, 'E:minmaj7': 322, 'E:maj6': 323, 'E:min6': 324, 'E:dim7': 325, 'E:hdim7': 326, 'E:maj9': 327, 'E:min9': 328, 'E:9': 329, 'E:min11': 330, 'E:11': 331, 'E:maj13': 332, 'E:min13': 333, 'E:13': 334, 'E:1': 335, 'E:5': 336, 'E:': 337, 'E:7(b9)': 338, 'E:7(#9)': 339, 'E:7(#11)': 340, 'E:7(b13)': 341, 'F:maj': 342, 'F:min': 343, 'F:aug': 344, 'F:dim': 345, 'F:sus4': 346, 'F:sus2': 347, 'F:7': 348, 'F:maj7': 349, 'F:min7': 350, 'F:minmaj7': 351, 'F:maj6': 352, 'F:min6': 353, 'F:dim7': 354, 'F:hdim7': 355, 'F:maj9': 356, 'F:min9': 357, 'F:9': 358, 'F:min11': 359, 'F:11': 360, 'F:maj13': 361, 'F:min13': 362, 'F:13': 363, 'F:1': 364, 'F:5': 365, 'F:': 366, 'F:7(b9)': 367, 'F:7(#9)': 368, 'F:7(#11)': 369, 'F:7(b13)': 370, 'F#:maj': 371, 'F#:min': 372, 'F#:aug': 373, 'F#:dim': 374, 'F#:sus4': 375, 'F#:sus2': 376, 'F#:7': 377, 'F#:maj7': 378, 'F#:min7': 379, 'F#:minmaj7': 380, 'F#:maj6': 381, 'F#:min6': 382, 'F#:dim7': 383, 'F#:hdim7': 384, 'F#:maj9': 385, 'F#:min9': 386, 'F#:9': 387, 'F#:min11': 388, 'F#:11': 389, 'F#:maj13': 390, 'F#:min13': 391, 'F#:13': 392, 'F#:1': 393, 'F#:5': 394, 'F#:': 395, 'F#:7(b9)': 396, 'F#:7(#9)': 397, 'F#:7(#11)': 398, 'F#:7(b13)': 399, 'G:maj': 400, 'G:min': 401, 'G:aug': 402, 'G:dim': 403, 'G:sus4': 404, 'G:sus2': 405, 'G:7': 406, 'G:maj7': 407, 'G:min7': 408, 'G:minmaj7': 409, 'G:maj6': 410, 'G:min6': 411, 'G:dim7': 412, 'G:hdim7': 413, 'G:maj9': 414, 'G:min9': 415, 'G:9': 416, 'G:min11': 417, 'G:11': 418, 'G:maj13': 419, 'G:min13': 420, 'G:13': 421, 'G:1': 422, 'G:5': 423, 'G:': 424, 'G:7(b9)': 425, 'G:7(#9)': 426, 'G:7(#11)': 427, 'G:7(b13)': 428, 'G#:maj': 429, 'G#:min': 430, 'G#:aug': 431, 'G#:dim': 432, 'G#:sus4': 433, 'G#:sus2': 434, 'G#:7': 435, 'G#:maj7': 436, 'G#:min7': 437, 'G#:minmaj7': 438, 'G#:maj6': 439, 'G#:min6': 440, 'G#:dim7': 441, 'G#:hdim7': 442, 'G#:maj9': 443, 'G#:min9': 444, 'G#:9': 445, 'G#:min11': 446, 'G#:11': 447, 'G#:maj13': 448, 'G#:min13': 449, 'G#:13': 450, 'G#:1': 451, 'G#:5': 452, 'G#:': 453, 'G#:7(b9)': 454, 'G#:7(#9)': 455, 'G#:7(#11)': 456, 'G#:7(b13)': 457, 'A:maj': 458, 'A:min': 459, 'A:aug': 460, 'A:dim': 461, 'A:sus4': 462, 'A:sus2': 463, 'A:7': 464, 'A:maj7': 465, 'A:min7': 466, 'A:minmaj7': 467, 'A:maj6': 468, 'A:min6': 469, 'A:dim7': 470, 'A:hdim7': 471, 'A:maj9': 472, 'A:min9': 473, 'A:9': 474, 'A:min11': 475, 'A:11': 476, 'A:maj13': 477, 'A:min13': 478, 'A:13': 479, 'A:1': 480, 'A:5': 481, 'A:': 482, 'A:7(b9)': 483, 'A:7(#9)': 484, 'A:7(#11)': 485, 'A:7(b13)': 486, 'A#:maj': 487, 'A#:min': 488, 'A#:aug': 489, 'A#:dim': 490, 'A#:sus4': 491, 'A#:sus2': 492, 'A#:7': 493, 'A#:maj7': 494, 'A#:min7': 495, 'A#:minmaj7': 496, 'A#:maj6': 497, 'A#:min6': 498, 'A#:dim7': 499, 'A#:hdim7': 500, 'A#:maj9': 501, 'A#:min9': 502, 'A#:9': 503, 'A#:min11': 504, 'A#:11': 505, 'A#:maj13': 506, 'A#:min13': 507, 'A#:13': 508, 'A#:1': 509, 'A#:5': 510, 'A#:': 511, 'A#:7(b9)': 512, 'A#:7(#9)': 513, 'A#:7(#11)': 514, 'A#:7(b13)': 515, 'B:maj': 516, 'B:min': 517, 'B:aug': 518, 'B:dim': 519, 'B:sus4': 520, 'B:sus2': 521, 'B:7': 522, 'B:maj7': 523, 'B:min7': 524, 'B:minmaj7': 525, 'B:maj6': 526, 'B:min6': 527, 'B:dim7': 528, 'B:hdim7': 529, 'B:maj9': 530, 'B:min9': 531, 'B:9': 532, 'B:min11': 533, 'B:11': 534, 'B:maj13': 535, 'B:min13': 536, 'B:13': 537, 'B:1': 538, 'B:5': 539, 'B:': 540, 'B:7(b9)': 541, 'B:7(#9)': 542, 'B:7(#11)': 543, 'B:7(b13)': 544}\n",
      "Training melody tokenizer\n",
      "Merging melody vocab\n",
      "Training harmony tokenizer\n",
      "Merging harmony vocab\n",
      "Processing melody\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Melody Files: 100%|██████████| 650/650 [00:31<00:00, 20.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing harmony\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files: 100%|██████████| 650/650 [00:48<00:00, 13.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example sentence length:  136\n",
      "['<s>', '<bar>', 'position_0x00', 'P:65', 'position_1x00', 'P:72', 'position_2x50', 'P:68', '<bar>', 'position_0x00', 'P:70', '<bar>', 'position_0x00', 'P:68', 'position_1x50', 'P:70', '<bar>', 'position_0x00', 'P:65', 'position_2x00', '<rest>', 'position_2x50', 'P:60', '<bar>', 'position_0x00', 'P:65', 'position_1x00', 'P:72', 'position_2x50', 'P:68', '<bar>', 'position_0x00', 'P:70', '<bar>', 'position_0x00', 'P:68', 'position_1x50', 'P:70', '<bar>', 'position_0x00', 'P:65', '<bar>', 'position_0x00', 'P:63', 'position_1x00', 'P:63', 'position_2x00', 'P:67', '<bar>', 'position_0x00', 'P:63', '<bar>', 'position_0x00', 'P:61', 'position_1x50', 'P:63', '<bar>', 'position_0x00', 'P:65', '<bar>', 'position_0x00', 'P:63', 'position_1x00', 'P:63', 'position_2x00', 'P:67', '<bar>', 'position_0x00', 'P:63', '<bar>', 'position_0x00', 'P:61', 'position_1x50', 'P:68', '<bar>', 'position_0x00', 'P:65', '</s>', '<h>', '<bar>', 'position_0x00', 'F:min7', '<bar>', 'position_0x00', 'G:min7', '<bar>', 'position_0x00', 'G#:maj7', 'position_1x50', 'G:min7', '<bar>', 'position_0x00', 'F:min7', '<bar>', 'position_0x00', 'F:min7', '<bar>', 'position_0x00', 'G:min7', '<bar>', 'position_0x00', 'G#:maj7', 'position_1x50', 'G:min7', '<bar>', 'position_0x00', 'F:min7', '<bar>', 'position_0x00', 'D#:maj', '<bar>', 'position_0x00', 'D#:maj', '<bar>', 'position_0x00', 'C#:maj', 'position_1x50', 'D#:maj', '<bar>', 'position_0x00', 'F:min7', '<bar>', 'position_0x00', 'D#:maj', '<bar>', 'position_0x00', 'D#:maj', '<bar>', 'position_0x00', 'C#:maj', 'position_1x50', 'D#:maj', '<bar>', 'position_0x00', 'F:min7', '</s>']\n",
      "[2, 6, 95, 51, 103, 58, 115, 54, 6, 95, 56, 6, 95, 54, 107, 56, 6, 95, 51, 111, 4, 115, 46, 6, 95, 51, 103, 58, 115, 54, 6, 95, 56, 6, 95, 54, 107, 56, 6, 95, 51, 6, 95, 49, 103, 49, 111, 53, 6, 95, 49, 6, 95, 47, 107, 49, 6, 95, 51, 6, 95, 49, 103, 49, 111, 53, 6, 95, 49, 6, 95, 47, 107, 54, 6, 95, 51, 3, 7, 6, 8, 261, 6, 8, 319, 6, 8, 347, 20, 319, 6, 8, 261, 6, 8, 261, 6, 8, 319, 6, 8, 347, 20, 319, 6, 8, 261, 6, 8, 195, 6, 8, 195, 6, 8, 137, 20, 195, 6, 8, 261, 6, 8, 195, 6, 8, 195, 6, 8, 137, 20, 195, 6, 8, 261, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Fixing combined MergedMelHarmTokenizer\n",
    "print('Length of combined vocab:', len(m_chordSymbolTokenizer.vocab))\n",
    "print('Combined vocab:', m_chordSymbolTokenizer.vocab)\n",
    "\n",
    "m_chordSymbolTokenizer.fit( data_files )\n",
    "toks_symb_m = m_chordSymbolTokenizer(data_files)\n",
    "print('example sentence length: ', len(toks_symb_m['tokens'][0]))\n",
    "print(toks_symb_m['tokens'][0])\n",
    "print(toks_symb_m['ids'][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 203]\n",
      "[180, 154]\n"
     ]
    }
   ],
   "source": [
    "print(m_chordSymbolTokenizer.convert_tokens_to_ids(['<mask>', 'C:7']))\n",
    "print(m_chordSymbolTokenizer.convert_tokens_to_ids(['ts_4x4', 'position_7x33']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
