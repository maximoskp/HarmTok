{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maximos/anaconda3/envs/midi/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import muspy\n",
    "from harmony_tokenizers import ChordSymbolTokenizer, RootTypeTokenizer, \\\n",
    "    PitchClassTokenizer, RootPCTokenizer, \\\n",
    "    GCTRootPCTokenizer, GCTSymbolTokenizer, GCTRootTypeTokenizer\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import zlib\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650\n"
     ]
    }
   ],
   "source": [
    "gjt_path = 'data/gjt_melodies/Library_melodies/'\n",
    "gjt_list = os.listdir(gjt_path)\n",
    "print(len(gjt_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 650/650 [00:09<00:00, 69.19it/s]\n"
     ]
    }
   ],
   "source": [
    "gjt_pieces = []\n",
    "for i in tqdm(range(len(gjt_list))):\n",
    "    g = muspy.read_musicxml(gjt_path + gjt_list[i])\n",
    "    gjt_pieces.append(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650\n"
     ]
    }
   ],
   "source": [
    "print(len(gjt_pieces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare stats\n",
    "stats = {}\n",
    "\n",
    "def compute_compression_rate(array: np.ndarray, compression_method=zlib.compress) -> float:\n",
    "    \"\"\"\n",
    "    Compute the compression rate of a NumPy array.\n",
    "\n",
    "    Parameters:\n",
    "        array (np.ndarray): The NumPy array to compress.\n",
    "        compression_method (callable): The compression method to use. \n",
    "                                       Default is `zlib.compress`.\n",
    "\n",
    "    Returns:\n",
    "        float: The compression rate (compressed size / original size).\n",
    "    \"\"\"\n",
    "    # Convert the array to bytes\n",
    "    array_bytes = array.tobytes()\n",
    "    \n",
    "    # Compress the byte representation\n",
    "    compressed_bytes = compression_method(array_bytes)\n",
    "    \n",
    "    # Compute sizes\n",
    "    original_size = len(array_bytes)\n",
    "    compressed_size = len(compressed_bytes)\n",
    "    \n",
    "    # Calculate compression rate\n",
    "    compression_rate = compressed_size / original_size\n",
    "\n",
    "    return compression_rate\n",
    "\n",
    "def initialize_stats(key, tokenizer):\n",
    "    stats[key] = {\n",
    "        'vocab_size': len(tokenizer.vocab),\n",
    "        'seq_lens': [],\n",
    "        'compression_rates': []\n",
    "    }\n",
    "# end initialize_stats\n",
    "\n",
    "def update_stats(key, toks):\n",
    "    for t in toks['ids']:\n",
    "        stats[key]['seq_lens'].append( len(t) )\n",
    "        stats[key]['compression_rates'].append( compute_compression_rate(np.array(t)) )\n",
    "    stats[key]['mean_len'] = np.mean(stats[key]['seq_lens'])\n",
    "    stats[key]['std_len'] = np.std(stats[key]['seq_lens'])\n",
    "    stats[key]['mean_compression'] = np.mean(stats[key]['compression_rates'])\n",
    "    stats[key]['std_compression'] = np.std(stats[key]['compression_rates'])\n",
    "# end update_stats\n",
    "\n",
    "def print_stats(key):\n",
    "    print('vocab_size: ', stats[key]['vocab_size'])\n",
    "    print('mean len: ', stats[key]['mean_len'])\n",
    "    print('std len: ', stats[key]['std_len'])\n",
    "    print('mean cr: ', stats[key]['mean_compression'])\n",
    "    print('std cr: ', stats[key]['std_compression'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChordSymbolTokenizer\n",
      "len(chordSymbolTokenizer.vocab):  322\n",
      "example sentence length:  104\n",
      "['bar', 'position_0x0', 'A:min7', 'bar', 'position_0x0', 'D:7', 'bar', 'position_0x0', 'A:min7', 'bar', 'position_0x0', 'D:7', 'bar', 'position_0x0', 'G:maj7', 'bar', 'position_0x0', 'C:7', 'bar', 'position_0x0', 'B:min7', 'bar', 'position_0x0', 'E:min7', 'bar', 'position_0x0', 'A:min7', 'bar', 'position_0x0', 'D:7', 'bar', 'position_0x0', 'A:min7', 'bar', 'position_0x0', 'D:7', 'bar', 'position_0x0', 'G:maj7', 'bar', 'position_0x0', 'C:7', 'bar', 'position_0x0', 'E:min7', 'bar', 'position_0x0', 'B:maj6', 'bar', 'position_0x0', 'D:min7', 'bar', 'position_0x0', 'G:7', 'bar', 'position_0x0', 'D:min7', 'bar', 'position_0x0', 'G:7', 'bar', 'position_0x0', 'C:maj7', 'bar', 'position_0x0', 'F:7', 'bar', 'position_0x0', 'E:min7', 'position_2x0', 'A:7', 'bar', 'position_0x0', 'A:min7', 'position_1x0', 'D:7', 'bar', 'position_0x0', 'A:min7', 'bar', 'position_0x0', 'D:7', 'bar', 'position_0x0', 'G:maj7', 'position_2x0', 'F:7', 'bar', 'position_0x0', 'E:7', 'bar', 'position_0x0', 'A:min7', 'bar', 'position_0x0', 'F:7', 'bar', 'position_0x0', 'A:min7', 'position_2x0', 'D:7', 'bar', 'position_0x0', 'G:maj6']\n",
      "[5, 6, 255, 5, 6, 78, 5, 6, 255, 5, 6, 78, 5, 6, 204, 5, 6, 28, 5, 6, 305, 5, 6, 130, 5, 6, 255, 5, 6, 78, 5, 6, 255, 5, 6, 78, 5, 6, 204, 5, 6, 28, 5, 6, 130, 5, 6, 307, 5, 6, 80, 5, 6, 203, 5, 6, 80, 5, 6, 203, 5, 6, 29, 5, 6, 153, 5, 6, 130, 10, 253, 5, 6, 255, 8, 78, 5, 6, 255, 5, 6, 78, 5, 6, 204, 10, 153, 5, 6, 128, 5, 6, 255, 5, 6, 153, 5, 6, 255, 10, 78, 5, 6, 207]\n",
      "vocab_size:  322\n",
      "mean len:  120.49230769230769\n",
      "std len:  43.32468583113863\n",
      "mean cr:  0.10251211948552254\n",
      "std cr:  0.027516088579421383\n"
     ]
    }
   ],
   "source": [
    "print('ChordSymbolTokenizer')\n",
    "chordSymbolTokenizer = ChordSymbolTokenizer()\n",
    "print('len(chordSymbolTokenizer.vocab): ', len(chordSymbolTokenizer.vocab))\n",
    "initialize_stats('ChordSymbolTokenizer', chordSymbolTokenizer)\n",
    "toks_cs = chordSymbolTokenizer(gjt_pieces)\n",
    "print('example sentence length: ', len(toks_cs['tokens'][0]))\n",
    "print(toks_cs['tokens'][0])\n",
    "print(toks_cs['ids'][0])\n",
    "update_stats('ChordSymbolTokenizer', toks_cs)\n",
    "print_stats('ChordSymbolTokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RootTypeTokenizer\n",
      "len(rootTypeTokenizer.vocab):  59\n",
      "example sentence length:  140\n",
      "['bar', 'position_0x0', 'A', 'min7', 'bar', 'position_0x0', 'D', '7', 'bar', 'position_0x0', 'A', 'min7', 'bar', 'position_0x0', 'D', '7', 'bar', 'position_0x0', 'G', 'maj7', 'bar', 'position_0x0', 'C', '7', 'bar', 'position_0x0', 'B', 'min7', 'bar', 'position_0x0', 'E', 'min7', 'bar', 'position_0x0', 'A', 'min7', 'bar', 'position_0x0', 'D', '7', 'bar', 'position_0x0', 'A', 'min7', 'bar', 'position_0x0', 'D', '7', 'bar', 'position_0x0', 'G', 'maj7', 'bar', 'position_0x0', 'C', '7', 'bar', 'position_0x0', 'E', 'min7', 'bar', 'position_0x0', 'B', 'maj6', 'bar', 'position_0x0', 'D', 'min7', 'bar', 'position_0x0', 'G', '7', 'bar', 'position_0x0', 'D', 'min7', 'bar', 'position_0x0', 'G', '7', 'bar', 'position_0x0', 'C', 'maj7', 'bar', 'position_0x0', 'F', '7', 'bar', 'position_0x0', 'E', 'min7', 'position_2x0', 'A', '7', 'bar', 'position_0x0', 'A', 'min7', 'position_1x0', 'D', '7', 'bar', 'position_0x0', 'A', 'min7', 'bar', 'position_0x0', 'D', '7', 'bar', 'position_0x0', 'G', 'maj7', 'position_2x0', 'F', '7', 'bar', 'position_0x0', 'E', '7', 'bar', 'position_0x0', 'A', 'min7', 'bar', 'position_0x0', 'F', '7', 'bar', 'position_0x0', 'A', 'min7', 'position_2x0', 'D', '7', 'bar', 'position_0x0', 'G', 'maj6']\n",
      "[5, 6, 31, 42, 5, 6, 24, 40, 5, 6, 31, 42, 5, 6, 24, 40, 5, 6, 29, 41, 5, 6, 22, 40, 5, 6, 33, 42, 5, 6, 26, 42, 5, 6, 31, 42, 5, 6, 24, 40, 5, 6, 31, 42, 5, 6, 24, 40, 5, 6, 29, 41, 5, 6, 22, 40, 5, 6, 26, 42, 5, 6, 33, 44, 5, 6, 24, 42, 5, 6, 29, 40, 5, 6, 24, 42, 5, 6, 29, 40, 5, 6, 22, 41, 5, 6, 27, 40, 5, 6, 26, 42, 10, 31, 40, 5, 6, 31, 42, 8, 24, 40, 5, 6, 31, 42, 5, 6, 24, 40, 5, 6, 29, 41, 10, 27, 40, 5, 6, 26, 40, 5, 6, 31, 42, 5, 6, 27, 40, 5, 6, 31, 42, 10, 24, 40, 5, 6, 29, 44]\n",
      "vocab_size:  59\n",
      "mean len:  164.8876923076923\n",
      "std len:  60.33976621584019\n",
      "mean cr:  0.09010761330663442\n",
      "std cr:  0.02333875516461699\n"
     ]
    }
   ],
   "source": [
    "print('RootTypeTokenizer')\n",
    "rootTypeTokenizer = RootTypeTokenizer()\n",
    "print('len(rootTypeTokenizer.vocab): ', len(rootTypeTokenizer.vocab))\n",
    "initialize_stats('RootTypeTokenizer', rootTypeTokenizer)\n",
    "toks_rt = rootTypeTokenizer(gjt_pieces)\n",
    "print('example sentence length: ', len(toks_rt['tokens'][0]))\n",
    "print(toks_rt['tokens'][0])\n",
    "print(toks_rt['ids'][0])\n",
    "update_stats('RootTypeTokenizer', toks_rt)\n",
    "print_stats('RootTypeTokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PitchClassTokenizer\n",
      "len(pitchClassTokenizer.vocab):  34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example sentence length:  212\n",
      "['bar', 'position_0x0', 'chord_pc_9', 'chord_pc_0', 'chord_pc_4', 'chord_pc_7', 'bar', 'position_0x0', 'chord_pc_2', 'chord_pc_6', 'chord_pc_9', 'chord_pc_0', 'bar', 'position_0x0', 'chord_pc_9', 'chord_pc_0', 'chord_pc_4', 'chord_pc_7', 'bar', 'position_0x0', 'chord_pc_2', 'chord_pc_6', 'chord_pc_9', 'chord_pc_0', 'bar', 'position_0x0', 'chord_pc_7', 'chord_pc_11', 'chord_pc_2', 'chord_pc_6', 'bar', 'position_0x0', 'chord_pc_0', 'chord_pc_4', 'chord_pc_7', 'chord_pc_10', 'bar', 'position_0x0', 'chord_pc_11', 'chord_pc_2', 'chord_pc_6', 'chord_pc_9', 'bar', 'position_0x0', 'chord_pc_4', 'chord_pc_7', 'chord_pc_11', 'chord_pc_2', 'bar', 'position_0x0', 'chord_pc_9', 'chord_pc_0', 'chord_pc_4', 'chord_pc_7', 'bar', 'position_0x0', 'chord_pc_2', 'chord_pc_6', 'chord_pc_9', 'chord_pc_0', 'bar', 'position_0x0', 'chord_pc_9', 'chord_pc_0', 'chord_pc_4', 'chord_pc_7', 'bar', 'position_0x0', 'chord_pc_2', 'chord_pc_6', 'chord_pc_9', 'chord_pc_0', 'bar', 'position_0x0', 'chord_pc_7', 'chord_pc_11', 'chord_pc_2', 'chord_pc_6', 'bar', 'position_0x0', 'chord_pc_0', 'chord_pc_4', 'chord_pc_7', 'chord_pc_10', 'bar', 'position_0x0', 'chord_pc_4', 'chord_pc_7', 'chord_pc_11', 'chord_pc_2', 'bar', 'position_0x0', 'chord_pc_11', 'chord_pc_3', 'chord_pc_6', 'chord_pc_8', 'bar', 'position_0x0', 'chord_pc_2', 'chord_pc_5', 'chord_pc_9', 'chord_pc_0', 'bar', 'position_0x0', 'chord_pc_7', 'chord_pc_11', 'chord_pc_2', 'chord_pc_5', 'bar', 'position_0x0', 'chord_pc_2', 'chord_pc_5', 'chord_pc_9', 'chord_pc_0', 'bar', 'position_0x0', 'chord_pc_7', 'chord_pc_11', 'chord_pc_2', 'chord_pc_5', 'bar', 'position_0x0', 'chord_pc_0', 'chord_pc_4', 'chord_pc_7', 'chord_pc_11', 'bar', 'position_0x0', 'chord_pc_5', 'chord_pc_9', 'chord_pc_0', 'chord_pc_3', 'bar', 'position_0x0', 'chord_pc_4', 'chord_pc_7', 'chord_pc_11', 'chord_pc_2', 'position_2x0', 'chord_pc_9', 'chord_pc_1', 'chord_pc_4', 'chord_pc_7', 'bar', 'position_0x0', 'chord_pc_9', 'chord_pc_0', 'chord_pc_4', 'chord_pc_7', 'position_1x0', 'chord_pc_2', 'chord_pc_6', 'chord_pc_9', 'chord_pc_0', 'bar', 'position_0x0', 'chord_pc_9', 'chord_pc_0', 'chord_pc_4', 'chord_pc_7', 'bar', 'position_0x0', 'chord_pc_2', 'chord_pc_6', 'chord_pc_9', 'chord_pc_0', 'bar', 'position_0x0', 'chord_pc_7', 'chord_pc_11', 'chord_pc_2', 'chord_pc_6', 'position_2x0', 'chord_pc_5', 'chord_pc_9', 'chord_pc_0', 'chord_pc_3', 'bar', 'position_0x0', 'chord_pc_4', 'chord_pc_8', 'chord_pc_11', 'chord_pc_2', 'bar', 'position_0x0', 'chord_pc_9', 'chord_pc_0', 'chord_pc_4', 'chord_pc_7', 'bar', 'position_0x0', 'chord_pc_5', 'chord_pc_9', 'chord_pc_0', 'chord_pc_3', 'bar', 'position_0x0', 'chord_pc_9', 'chord_pc_0', 'chord_pc_4', 'chord_pc_7', 'position_2x0', 'chord_pc_2', 'chord_pc_6', 'chord_pc_9', 'chord_pc_0', 'bar', 'position_0x0', 'chord_pc_7', 'chord_pc_11', 'chord_pc_2', 'chord_pc_4']\n",
      "[5, 7, 32, 23, 27, 30, 5, 7, 25, 29, 32, 23, 5, 7, 32, 23, 27, 30, 5, 7, 25, 29, 32, 23, 5, 7, 30, 34, 25, 29, 5, 7, 23, 27, 30, 33, 5, 7, 34, 25, 29, 32, 5, 7, 27, 30, 34, 25, 5, 7, 32, 23, 27, 30, 5, 7, 25, 29, 32, 23, 5, 7, 32, 23, 27, 30, 5, 7, 25, 29, 32, 23, 5, 7, 30, 34, 25, 29, 5, 7, 23, 27, 30, 33, 5, 7, 27, 30, 34, 25, 5, 7, 34, 26, 29, 31, 5, 7, 25, 28, 32, 23, 5, 7, 30, 34, 25, 28, 5, 7, 25, 28, 32, 23, 5, 7, 30, 34, 25, 28, 5, 7, 23, 27, 30, 34, 5, 7, 28, 32, 23, 26, 5, 7, 27, 30, 34, 25, 11, 32, 24, 27, 30, 5, 7, 32, 23, 27, 30, 9, 25, 29, 32, 23, 5, 7, 32, 23, 27, 30, 5, 7, 25, 29, 32, 23, 5, 7, 30, 34, 25, 29, 11, 28, 32, 23, 26, 5, 7, 27, 31, 34, 25, 5, 7, 32, 23, 27, 30, 5, 7, 28, 32, 23, 26, 5, 7, 32, 23, 27, 30, 11, 25, 29, 32, 23, 5, 7, 30, 34, 25, 27]\n",
      "vocab_size:  34\n",
      "mean len:  254.32153846153847\n",
      "std len:  94.77219487122822\n",
      "mean cr:  0.07775146860064301\n",
      "std cr:  0.021220243840106214\n"
     ]
    }
   ],
   "source": [
    "print('PitchClassTokenizer')\n",
    "pitchClassTokenizer = PitchClassTokenizer()\n",
    "print('len(pitchClassTokenizer.vocab): ', len(pitchClassTokenizer.vocab))\n",
    "initialize_stats('PitchClassTokenizer', pitchClassTokenizer)\n",
    "toks_pc = pitchClassTokenizer(gjt_pieces)\n",
    "print('example sentence length: ', len(toks_pc['tokens'][0]))\n",
    "print(toks_pc['tokens'][0])\n",
    "print(toks_pc['ids'][0])\n",
    "update_stats('PitchClassTokenizer', toks_pc)\n",
    "print_stats('PitchClassTokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RootPCTokenizer\n",
      "len(rootPCTokenizer.vocab):  46\n",
      "example sentence length:  212\n",
      "['bar', 'position_0x0', 'chord_root_9', 'chord_pc_0', 'chord_pc_4', 'chord_pc_7', 'bar', 'position_0x0', 'chord_root_2', 'chord_pc_6', 'chord_pc_9', 'chord_pc_0', 'bar', 'position_0x0', 'chord_root_9', 'chord_pc_0', 'chord_pc_4', 'chord_pc_7', 'bar', 'position_0x0', 'chord_root_2', 'chord_pc_6', 'chord_pc_9', 'chord_pc_0', 'bar', 'position_0x0', 'chord_root_7', 'chord_pc_11', 'chord_pc_2', 'chord_pc_6', 'bar', 'position_0x0', 'chord_root_0', 'chord_pc_4', 'chord_pc_7', 'chord_pc_10', 'bar', 'position_0x0', 'chord_root_11', 'chord_pc_2', 'chord_pc_6', 'chord_pc_9', 'bar', 'position_0x0', 'chord_root_4', 'chord_pc_7', 'chord_pc_11', 'chord_pc_2', 'bar', 'position_0x0', 'chord_root_9', 'chord_pc_0', 'chord_pc_4', 'chord_pc_7', 'bar', 'position_0x0', 'chord_root_2', 'chord_pc_6', 'chord_pc_9', 'chord_pc_0', 'bar', 'position_0x0', 'chord_root_9', 'chord_pc_0', 'chord_pc_4', 'chord_pc_7', 'bar', 'position_0x0', 'chord_root_2', 'chord_pc_6', 'chord_pc_9', 'chord_pc_0', 'bar', 'position_0x0', 'chord_root_7', 'chord_pc_11', 'chord_pc_2', 'chord_pc_6', 'bar', 'position_0x0', 'chord_root_0', 'chord_pc_4', 'chord_pc_7', 'chord_pc_10', 'bar', 'position_0x0', 'chord_root_4', 'chord_pc_7', 'chord_pc_11', 'chord_pc_2', 'bar', 'position_0x0', 'chord_root_11', 'chord_pc_3', 'chord_pc_6', 'chord_pc_8', 'bar', 'position_0x0', 'chord_root_2', 'chord_pc_5', 'chord_pc_9', 'chord_pc_0', 'bar', 'position_0x0', 'chord_root_7', 'chord_pc_11', 'chord_pc_2', 'chord_pc_5', 'bar', 'position_0x0', 'chord_root_2', 'chord_pc_5', 'chord_pc_9', 'chord_pc_0', 'bar', 'position_0x0', 'chord_root_7', 'chord_pc_11', 'chord_pc_2', 'chord_pc_5', 'bar', 'position_0x0', 'chord_root_0', 'chord_pc_4', 'chord_pc_7', 'chord_pc_11', 'bar', 'position_0x0', 'chord_root_5', 'chord_pc_9', 'chord_pc_0', 'chord_pc_3', 'bar', 'position_0x0', 'chord_root_4', 'chord_pc_7', 'chord_pc_11', 'chord_pc_2', 'position_2x0', 'chord_root_9', 'chord_pc_1', 'chord_pc_4', 'chord_pc_7', 'bar', 'position_0x0', 'chord_root_9', 'chord_pc_0', 'chord_pc_4', 'chord_pc_7', 'position_1x0', 'chord_root_2', 'chord_pc_6', 'chord_pc_9', 'chord_pc_0', 'bar', 'position_0x0', 'chord_root_9', 'chord_pc_0', 'chord_pc_4', 'chord_pc_7', 'bar', 'position_0x0', 'chord_root_2', 'chord_pc_6', 'chord_pc_9', 'chord_pc_0', 'bar', 'position_0x0', 'chord_root_7', 'chord_pc_11', 'chord_pc_2', 'chord_pc_6', 'position_2x0', 'chord_root_5', 'chord_pc_9', 'chord_pc_0', 'chord_pc_3', 'bar', 'position_0x0', 'chord_root_4', 'chord_pc_8', 'chord_pc_11', 'chord_pc_2', 'bar', 'position_0x0', 'chord_root_9', 'chord_pc_0', 'chord_pc_4', 'chord_pc_7', 'bar', 'position_0x0', 'chord_root_5', 'chord_pc_9', 'chord_pc_0', 'chord_pc_3', 'bar', 'position_0x0', 'chord_root_9', 'chord_pc_0', 'chord_pc_4', 'chord_pc_7', 'position_2x0', 'chord_root_2', 'chord_pc_6', 'chord_pc_9', 'chord_pc_0', 'bar', 'position_0x0', 'chord_root_7', 'chord_pc_11', 'chord_pc_2', 'chord_pc_4']\n",
      "[5, 7, 32, 35, 39, 42, 5, 7, 25, 41, 44, 35, 5, 7, 32, 35, 39, 42, 5, 7, 25, 41, 44, 35, 5, 7, 30, 46, 37, 41, 5, 7, 23, 39, 42, 45, 5, 7, 34, 37, 41, 44, 5, 7, 27, 42, 46, 37, 5, 7, 32, 35, 39, 42, 5, 7, 25, 41, 44, 35, 5, 7, 32, 35, 39, 42, 5, 7, 25, 41, 44, 35, 5, 7, 30, 46, 37, 41, 5, 7, 23, 39, 42, 45, 5, 7, 27, 42, 46, 37, 5, 7, 34, 38, 41, 43, 5, 7, 25, 40, 44, 35, 5, 7, 30, 46, 37, 40, 5, 7, 25, 40, 44, 35, 5, 7, 30, 46, 37, 40, 5, 7, 23, 39, 42, 46, 5, 7, 28, 44, 35, 38, 5, 7, 27, 42, 46, 37, 11, 32, 36, 39, 42, 5, 7, 32, 35, 39, 42, 9, 25, 41, 44, 35, 5, 7, 32, 35, 39, 42, 5, 7, 25, 41, 44, 35, 5, 7, 30, 46, 37, 41, 11, 28, 44, 35, 38, 5, 7, 27, 43, 46, 37, 5, 7, 32, 35, 39, 42, 5, 7, 28, 44, 35, 38, 5, 7, 32, 35, 39, 42, 11, 25, 41, 44, 35, 5, 7, 30, 46, 37, 39]\n",
      "vocab_size:  46\n",
      "mean len:  254.32153846153847\n",
      "std len:  94.77219487122822\n",
      "mean cr:  0.084217979630103\n",
      "std cr:  0.023634596853205788\n"
     ]
    }
   ],
   "source": [
    "print('RootPCTokenizer')\n",
    "rootPCTokenizer = RootPCTokenizer()\n",
    "print('len(rootPCTokenizer.vocab): ', len(rootPCTokenizer.vocab))\n",
    "initialize_stats('RootPCTokenizer', rootPCTokenizer)\n",
    "toks_rpc = rootPCTokenizer(gjt_pieces)\n",
    "print('example sentence length: ', len(toks_rpc['tokens'][0]))\n",
    "print(toks_rpc['tokens'][0])\n",
    "print(toks_rpc['ids'][0])\n",
    "update_stats('RootPCTokenizer', toks_rpc)\n",
    "print_stats('RootPCTokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCTRootPCTokenizer\n",
      "len(gctRootPCTokenizer.vocab):  46\n",
      "example sentence length:  212\n",
      "['bar', 'position_0x0', 'chord_root_0', 'chord_pc_4', 'chord_pc_7', 'chord_pc_9', 'bar', 'position_0x0', 'chord_root_2', 'chord_pc_6', 'chord_pc_9', 'chord_pc_0', 'bar', 'position_0x0', 'chord_root_0', 'chord_pc_4', 'chord_pc_7', 'chord_pc_9', 'bar', 'position_0x0', 'chord_root_2', 'chord_pc_6', 'chord_pc_9', 'chord_pc_0', 'bar', 'position_0x0', 'chord_root_7', 'chord_pc_11', 'chord_pc_2', 'chord_pc_6', 'bar', 'position_0x0', 'chord_root_0', 'chord_pc_4', 'chord_pc_7', 'chord_pc_10', 'bar', 'position_0x0', 'chord_root_2', 'chord_pc_6', 'chord_pc_9', 'chord_pc_11', 'bar', 'position_0x0', 'chord_root_7', 'chord_pc_11', 'chord_pc_2', 'chord_pc_4', 'bar', 'position_0x0', 'chord_root_0', 'chord_pc_4', 'chord_pc_7', 'chord_pc_9', 'bar', 'position_0x0', 'chord_root_2', 'chord_pc_6', 'chord_pc_9', 'chord_pc_0', 'bar', 'position_0x0', 'chord_root_0', 'chord_pc_4', 'chord_pc_7', 'chord_pc_9', 'bar', 'position_0x0', 'chord_root_2', 'chord_pc_6', 'chord_pc_9', 'chord_pc_0', 'bar', 'position_0x0', 'chord_root_7', 'chord_pc_11', 'chord_pc_2', 'chord_pc_6', 'bar', 'position_0x0', 'chord_root_0', 'chord_pc_4', 'chord_pc_7', 'chord_pc_10', 'bar', 'position_0x0', 'chord_root_7', 'chord_pc_11', 'chord_pc_2', 'chord_pc_4', 'bar', 'position_0x0', 'chord_root_8', 'chord_pc_11', 'chord_pc_3', 'chord_pc_6', 'bar', 'position_0x0', 'chord_root_5', 'chord_pc_9', 'chord_pc_0', 'chord_pc_2', 'bar', 'position_0x0', 'chord_root_7', 'chord_pc_11', 'chord_pc_2', 'chord_pc_5', 'bar', 'position_0x0', 'chord_root_5', 'chord_pc_9', 'chord_pc_0', 'chord_pc_2', 'bar', 'position_0x0', 'chord_root_7', 'chord_pc_11', 'chord_pc_2', 'chord_pc_5', 'bar', 'position_0x0', 'chord_root_4', 'chord_pc_7', 'chord_pc_11', 'chord_pc_0', 'bar', 'position_0x0', 'chord_root_5', 'chord_pc_9', 'chord_pc_0', 'chord_pc_3', 'bar', 'position_0x0', 'chord_root_7', 'chord_pc_11', 'chord_pc_2', 'chord_pc_4', 'position_2x0', 'chord_root_9', 'chord_pc_1', 'chord_pc_4', 'chord_pc_7', 'bar', 'position_0x0', 'chord_root_0', 'chord_pc_4', 'chord_pc_7', 'chord_pc_9', 'position_1x0', 'chord_root_2', 'chord_pc_6', 'chord_pc_9', 'chord_pc_0', 'bar', 'position_0x0', 'chord_root_0', 'chord_pc_4', 'chord_pc_7', 'chord_pc_9', 'bar', 'position_0x0', 'chord_root_2', 'chord_pc_6', 'chord_pc_9', 'chord_pc_0', 'bar', 'position_0x0', 'chord_root_7', 'chord_pc_11', 'chord_pc_2', 'chord_pc_6', 'position_2x0', 'chord_root_5', 'chord_pc_9', 'chord_pc_0', 'chord_pc_3', 'bar', 'position_0x0', 'chord_root_4', 'chord_pc_8', 'chord_pc_11', 'chord_pc_2', 'bar', 'position_0x0', 'chord_root_0', 'chord_pc_4', 'chord_pc_7', 'chord_pc_9', 'bar', 'position_0x0', 'chord_root_5', 'chord_pc_9', 'chord_pc_0', 'chord_pc_3', 'bar', 'position_0x0', 'chord_root_0', 'chord_pc_4', 'chord_pc_7', 'chord_pc_9', 'position_2x0', 'chord_root_2', 'chord_pc_6', 'chord_pc_9', 'chord_pc_0', 'bar', 'position_0x0', 'chord_root_7', 'chord_pc_11', 'chord_pc_2', 'chord_pc_4']\n",
      "[5, 7, 23, 39, 42, 44, 5, 7, 25, 41, 44, 35, 5, 7, 23, 39, 42, 44, 5, 7, 25, 41, 44, 35, 5, 7, 30, 46, 37, 41, 5, 7, 23, 39, 42, 45, 5, 7, 25, 41, 44, 46, 5, 7, 30, 46, 37, 39, 5, 7, 23, 39, 42, 44, 5, 7, 25, 41, 44, 35, 5, 7, 23, 39, 42, 44, 5, 7, 25, 41, 44, 35, 5, 7, 30, 46, 37, 41, 5, 7, 23, 39, 42, 45, 5, 7, 30, 46, 37, 39, 5, 7, 31, 46, 38, 41, 5, 7, 28, 44, 35, 37, 5, 7, 30, 46, 37, 40, 5, 7, 28, 44, 35, 37, 5, 7, 30, 46, 37, 40, 5, 7, 27, 42, 46, 35, 5, 7, 28, 44, 35, 38, 5, 7, 30, 46, 37, 39, 11, 32, 36, 39, 42, 5, 7, 23, 39, 42, 44, 9, 25, 41, 44, 35, 5, 7, 23, 39, 42, 44, 5, 7, 25, 41, 44, 35, 5, 7, 30, 46, 37, 41, 11, 28, 44, 35, 38, 5, 7, 27, 43, 46, 37, 5, 7, 23, 39, 42, 44, 5, 7, 28, 44, 35, 38, 5, 7, 23, 39, 42, 44, 11, 25, 41, 44, 35, 5, 7, 30, 46, 37, 39]\n",
      "vocab_size:  46\n",
      "mean len:  254.32153846153847\n",
      "std len:  94.77219487122822\n",
      "mean cr:  0.08337781324743442\n",
      "std cr:  0.023224990226902966\n"
     ]
    }
   ],
   "source": [
    "print('GCTRootPCTokenizer')\n",
    "gctRootPCTokenizer = GCTRootPCTokenizer()\n",
    "print('len(gctRootPCTokenizer.vocab): ', len(gctRootPCTokenizer.vocab))\n",
    "initialize_stats('GCTRootPCTokenizer', gctRootPCTokenizer)\n",
    "toks_gct_rpc = gctRootPCTokenizer(gjt_pieces)\n",
    "print('example sentence length: ', len(toks_gct_rpc['tokens'][0]))\n",
    "print(toks_gct_rpc['tokens'][0])\n",
    "print(toks_gct_rpc['ids'][0])\n",
    "update_stats('GCTRootPCTokenizer', toks_gct_rpc)\n",
    "print_stats('GCTRootPCTokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCTSymbolTokenizer\n",
      "training\n",
      "len(gctSymbolTokenizer.vocab):  210\n",
      "example sentence length:  104\n",
      "['bar', 'position_0x0', '[0 0 4 7 9]', 'bar', 'position_0x0', '[ 2  0  4  7 10]', 'bar', 'position_0x0', '[0 0 4 7 9]', 'bar', 'position_0x0', '[ 2  0  4  7 10]', 'bar', 'position_0x0', '[ 7  0  4  7 11]', 'bar', 'position_0x0', '[ 0  0  4  7 10]', 'bar', 'position_0x0', '[2 0 4 7 9]', 'bar', 'position_0x0', '[7 0 4 7 9]', 'bar', 'position_0x0', '[0 0 4 7 9]', 'bar', 'position_0x0', '[ 2  0  4  7 10]', 'bar', 'position_0x0', '[0 0 4 7 9]', 'bar', 'position_0x0', '[ 2  0  4  7 10]', 'bar', 'position_0x0', '[ 7  0  4  7 11]', 'bar', 'position_0x0', '[ 0  0  4  7 10]', 'bar', 'position_0x0', '[7 0 4 7 9]', 'bar', 'position_0x0', '[ 8  0  3  7 10]', 'bar', 'position_0x0', '[5 0 4 7 9]', 'bar', 'position_0x0', '[ 7  0  4  7 10]', 'bar', 'position_0x0', '[5 0 4 7 9]', 'bar', 'position_0x0', '[ 7  0  4  7 10]', 'bar', 'position_0x0', '[4 0 3 7 8]', 'bar', 'position_0x0', '[ 5  0  4  7 10]', 'bar', 'position_0x0', '[7 0 4 7 9]', 'position_2x0', '[ 9  0  4  7 10]', 'bar', 'position_0x0', '[0 0 4 7 9]', 'position_1x0', '[ 2  0  4  7 10]', 'bar', 'position_0x0', '[0 0 4 7 9]', 'bar', 'position_0x0', '[ 2  0  4  7 10]', 'bar', 'position_0x0', '[ 7  0  4  7 11]', 'position_2x0', '[ 5  0  4  7 10]', 'bar', 'position_0x0', '[ 4  0  4  7 10]', 'bar', 'position_0x0', '[0 0 4 7 9]', 'bar', 'position_0x0', '[ 5  0  4  7 10]', 'bar', 'position_0x0', '[0 0 4 7 9]', 'position_2x0', '[ 2  0  4  7 10]', 'bar', 'position_0x0', '[7 0 4 7 9]']\n",
      "[5, 7, 22, 5, 7, 23, 5, 7, 22, 5, 7, 23, 5, 7, 24, 5, 7, 25, 5, 7, 26, 5, 7, 27, 5, 7, 22, 5, 7, 23, 5, 7, 22, 5, 7, 23, 5, 7, 24, 5, 7, 25, 5, 7, 27, 5, 7, 28, 5, 7, 29, 5, 7, 30, 5, 7, 29, 5, 7, 30, 5, 7, 31, 5, 7, 32, 5, 7, 27, 11, 33, 5, 7, 22, 9, 23, 5, 7, 22, 5, 7, 23, 5, 7, 24, 11, 32, 5, 7, 34, 5, 7, 22, 5, 7, 32, 5, 7, 22, 11, 23, 5, 7, 27]\n",
      "vocab_size:  210\n",
      "mean len:  120.49230769230769\n",
      "std len:  43.32468583113863\n",
      "mean cr:  0.09803812941427888\n",
      "std cr:  0.02641694129659591\n"
     ]
    }
   ],
   "source": [
    "print('GCTSymbolTokenizer')\n",
    "gctSymbolTokenizer = GCTSymbolTokenizer()\n",
    "print('training')\n",
    "gctSymbolTokenizer.fit( gjt_pieces )\n",
    "print('len(gctSymbolTokenizer.vocab): ', len(gctSymbolTokenizer.vocab))\n",
    "initialize_stats('GCTSymbolTokenizer', gctSymbolTokenizer)\n",
    "toks_gct_symb = gctSymbolTokenizer(gjt_pieces)\n",
    "print('example sentence length: ', len(toks_gct_symb['tokens'][0]))\n",
    "print(toks_gct_symb['tokens'][0])\n",
    "print(toks_gct_symb['ids'][0])\n",
    "update_stats('GCTSymbolTokenizer', toks_gct_symb)\n",
    "print_stats('GCTSymbolTokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCTRootTypeTokenizer\n",
      "training\n",
      "len(gctRootTypeTokenizer.vocab):  68\n",
      "example sentence length:  140\n",
      "['bar', 'position_0x0', 'chord_root_0', '[0 4 7 9]', 'bar', 'position_0x0', 'chord_root_2', '[ 0  4  7 10]', 'bar', 'position_0x0', 'chord_root_0', '[0 4 7 9]', 'bar', 'position_0x0', 'chord_root_2', '[ 0  4  7 10]', 'bar', 'position_0x0', 'chord_root_7', '[ 0  4  7 11]', 'bar', 'position_0x0', 'chord_root_0', '[ 0  4  7 10]', 'bar', 'position_0x0', 'chord_root_2', '[0 4 7 9]', 'bar', 'position_0x0', 'chord_root_7', '[0 4 7 9]', 'bar', 'position_0x0', 'chord_root_0', '[0 4 7 9]', 'bar', 'position_0x0', 'chord_root_2', '[ 0  4  7 10]', 'bar', 'position_0x0', 'chord_root_0', '[0 4 7 9]', 'bar', 'position_0x0', 'chord_root_2', '[ 0  4  7 10]', 'bar', 'position_0x0', 'chord_root_7', '[ 0  4  7 11]', 'bar', 'position_0x0', 'chord_root_0', '[ 0  4  7 10]', 'bar', 'position_0x0', 'chord_root_7', '[0 4 7 9]', 'bar', 'position_0x0', 'chord_root_8', '[ 0  3  7 10]', 'bar', 'position_0x0', 'chord_root_5', '[0 4 7 9]', 'bar', 'position_0x0', 'chord_root_7', '[ 0  4  7 10]', 'bar', 'position_0x0', 'chord_root_5', '[0 4 7 9]', 'bar', 'position_0x0', 'chord_root_7', '[ 0  4  7 10]', 'bar', 'position_0x0', 'chord_root_4', '[0 3 7 8]', 'bar', 'position_0x0', 'chord_root_5', '[ 0  4  7 10]', 'bar', 'position_0x0', 'chord_root_7', '[0 4 7 9]', 'position_2x0', 'chord_root_9', '[ 0  4  7 10]', 'bar', 'position_0x0', 'chord_root_0', '[0 4 7 9]', 'position_1x0', 'chord_root_2', '[ 0  4  7 10]', 'bar', 'position_0x0', 'chord_root_0', '[0 4 7 9]', 'bar', 'position_0x0', 'chord_root_2', '[ 0  4  7 10]', 'bar', 'position_0x0', 'chord_root_7', '[ 0  4  7 11]', 'position_2x0', 'chord_root_5', '[ 0  4  7 10]', 'bar', 'position_0x0', 'chord_root_4', '[ 0  4  7 10]', 'bar', 'position_0x0', 'chord_root_0', '[0 4 7 9]', 'bar', 'position_0x0', 'chord_root_5', '[ 0  4  7 10]', 'bar', 'position_0x0', 'chord_root_0', '[0 4 7 9]', 'position_2x0', 'chord_root_2', '[ 0  4  7 10]', 'bar', 'position_0x0', 'chord_root_7', '[0 4 7 9]']\n",
      "[5, 7, 23, 34, 5, 7, 25, 35, 5, 7, 23, 34, 5, 7, 25, 35, 5, 7, 30, 36, 5, 7, 23, 35, 5, 7, 25, 34, 5, 7, 30, 34, 5, 7, 23, 34, 5, 7, 25, 35, 5, 7, 23, 34, 5, 7, 25, 35, 5, 7, 30, 36, 5, 7, 23, 35, 5, 7, 30, 34, 5, 7, 31, 37, 5, 7, 28, 34, 5, 7, 30, 35, 5, 7, 28, 34, 5, 7, 30, 35, 5, 7, 27, 38, 5, 7, 28, 35, 5, 7, 30, 34, 11, 32, 35, 5, 7, 23, 34, 9, 25, 35, 5, 7, 23, 34, 5, 7, 25, 35, 5, 7, 30, 36, 11, 28, 35, 5, 7, 27, 35, 5, 7, 23, 34, 5, 7, 28, 35, 5, 7, 23, 34, 11, 25, 35, 5, 7, 30, 34]\n",
      "vocab_size:  322\n",
      "mean len:  164.8876923076923\n",
      "std len:  60.33976621584019\n",
      "mean cr:  0.08943318094180418\n",
      "std cr:  0.023651626067386328\n"
     ]
    }
   ],
   "source": [
    "print('GCTRootTypeTokenizer')\n",
    "gctRootTypeTokenizer = GCTRootTypeTokenizer()\n",
    "print('training')\n",
    "gctRootTypeTokenizer.fit( gjt_pieces )\n",
    "print('len(gctRootTypeTokenizer.vocab): ', len(gctRootTypeTokenizer.vocab))\n",
    "initialize_stats('GCTRootTypeTokenizer', chordSymbolTokenizer)\n",
    "toks_gct_rt = gctRootTypeTokenizer(gjt_pieces)\n",
    "print('example sentence length: ', len(toks_gct_rt['tokens'][0]))\n",
    "print(toks_gct_rt['tokens'][0])\n",
    "print(toks_gct_rt['ids'][0])\n",
    "update_stats('GCTRootTypeTokenizer', toks_gct_rt)\n",
    "print_stats('GCTRootTypeTokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print stats\n",
    "tokenizers = ['ChordSymbolTokenizer', 'GCTSymbolTokenizer',\\\n",
    "              'RootTypeTokenizer', 'GCTRootTypeTokenizer',\\\n",
    "              'PitchClassTokenizer', 'RootPCTokenizer', 'GCTRootPCTokenizer'\n",
    "              ]\n",
    "\n",
    "results_path = 'vocab_stats.csv'\n",
    "\n",
    "result_fields = ['Tokenizer', 'vocab_size'] + list( stats['ChordSymbolTokenizer'].keys() )[3:]\n",
    "\n",
    "with open( results_path, 'w' ) as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow( result_fields )\n",
    "\n",
    "for tok in tokenizers:\n",
    "    with open( results_path, 'a' ) as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow( [tok] + [stats[tok]['vocab_size']] + list( stats[tok].values() )[3:] )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "midi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
