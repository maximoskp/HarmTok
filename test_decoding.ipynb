{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER OPTIONS\n",
    "# define tokenizer name - should be one among the keys in the cell below\n",
    "tokenizer_name = 'ChordSymbolTokenizer' # or any other name from the keys in tokenizers dictionary\n",
    "# tokenizer_name = 'RootTypeTokenizer'\n",
    "# tokenizer_name = 'PitchClassTokenizer'\n",
    "csvs_folder = 'tokenized/gpt/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import MergedMelHarmDataset, PureGenCollator\n",
    "import os\n",
    "import numpy as np\n",
    "from harmony_tokenizers_m21 import ChordSymbolTokenizer, RootTypeTokenizer, \\\n",
    "    PitchClassTokenizer, RootPCTokenizer, GCTRootPCTokenizer, \\\n",
    "    GCTSymbolTokenizer, GCTRootTypeTokenizer, MelodyPitchTokenizer, \\\n",
    "    MergedMelHarmTokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizers = {\n",
    "    'ChordSymbolTokenizer': ChordSymbolTokenizer,\n",
    "    'RootTypeTokenizer': RootTypeTokenizer,\n",
    "    'PitchClassTokenizer': PitchClassTokenizer,\n",
    "    'RootPCTokenizer': RootPCTokenizer,\n",
    "    'GCTRootPCTokenizer': GCTRootPCTokenizer,\n",
    "    'GCTSymbolTokenizer': GCTSymbolTokenizer,\n",
    "    'GCTRootTypeTokenizer': GCTRootTypeTokenizer\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "melody_tokenizer = MelodyPitchTokenizer.from_pretrained('saved_tokenizers/MelodyPitchTokenizer')\n",
    "harmony_tokenizer = tokenizers[tokenizer_name].from_pretrained('saved_tokenizers/' + tokenizer_name)\n",
    "\n",
    "tokenizer = MergedMelHarmTokenizer(melody_tokenizer, harmony_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.read_csv( csvs_folder + tokenizer_name + '.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', '<bar>', 'ts_4x4', 'position_0x00', 'P:69', 'position_1x00', 'P:69', 'position_1x50', 'P:69', 'position_2x00', 'P:69', 'position_3x00', 'P:69', 'position_3x50', 'P:69', '<bar>', 'position_0x00', 'P:69', 'position_0x50', 'P:69', 'position_1x00', 'P:69', 'position_1x50', 'P:69', 'position_2x00', 'P:69', '<bar>', 'position_0x00', 'P:57', 'position_1x00', 'P:57', 'position_2x00', 'P:57', 'position_2x50', 'P:57', 'position_2x75', 'P:57', 'position_3x00', 'P:58', '<bar>', 'position_0x00', 'P:57', 'position_0x50', 'P:62', 'position_1x00', 'P:60', 'position_1x50', 'P:76', 'position_2x00', 'P:60', 'position_2x25', 'P:60', 'position_2x50', 'P:59', 'position_3x00', '<rest>', 'position_3x50', 'P:74', 'position_3x75', 'P:74', '<bar>', 'position_0x00', 'P:81', 'position_0x50', 'P:76', 'position_1x00', 'P:57', 'position_1x50', 'P:57', 'position_2x00', 'P:81', 'position_2x50', 'P:76', 'position_3x00', 'P:57', 'position_3x50', 'P:57', '<bar>', 'position_0x00', 'P:69', 'position_0x50', 'P:69', 'position_1x00', '<rest>', 'position_1x25', 'P:72', 'position_1x75', 'P:72', 'position_2x00', 'P:81', 'position_2x50', 'P:81', 'position_2x75', '<rest>', 'position_3x25', 'P:84', 'position_3x75', 'P:84', '<bar>', 'position_0x00', 'P:81', 'position_0x50', 'P:74', 'position_1x00', 'P:88', 'position_2x00', 'P:86', 'position_3x00', '<rest>', '<bar>', 'position_0x00', 'P:91', 'position_0x50', 'P:91', 'position_1x00', 'P:89', 'position_1x50', 'P:89', 'position_2x00', 'P:88', 'position_2x50', 'P:84', 'position_3x00', '<rest>', '<h>', '<h>', '<bar>', '<bar>', 'position_3x00', 'A:min', '<bar>', 'position_0x00', 'A:min', 'position_3x00', 'G:min', '<bar>', 'position_0x00', 'A:min', '<bar>', 'position_0x00', 'A:min', '<bar>', 'position_0x00', 'F:maj', '<bar>', 'position_0x00', 'D:min', '<bar>', 'position_0x00', 'F:maj', '</s>']\n"
     ]
    }
   ],
   "source": [
    "x = c['melody'].iloc[0].split() + c['real'].iloc[0].split()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A:min']\n",
      "['A:min']\n",
      "['G:min']\n",
      "['A:min']\n",
      "['A:min']\n",
      "['F:maj']\n",
      "['D:min']\n",
      "['F:maj']\n",
      "Saved as test.mxl\n"
     ]
    }
   ],
   "source": [
    "tokenizer.decode(x, output_format='file', output_path='test.mxl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
